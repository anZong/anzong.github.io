<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[nano命令]]></title>
    <url>%2F2018%2F08%2F23%2FLinux%2Fnano%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[用法: nano [选项] [[+行,列] 文件名]…12345678910111213141516171819202122232425262728293031323334353637383940414243选项 GNU 长选项 意义 -h, -? --help 显示此信息 +行,列 从所指列数与行数开始 -A --smarthome 启用智能 HOME 键 -B --backup 储存既有文件的备份 -C &lt;目录&gt; --backupdir=&lt;目录&gt; 用以储存独一备份文件的目录 -D --boldtext 用粗体替代颜色反转 -E --tabstospaces 将已输入的制表符转换为空白 -F --multibuffer 启用多重文件缓冲区功能 -H --historylog 记录与读取搜索/替换的历史字符串 -I --ignorercfiles 不要参考nanorc 文件 -K --rebindkeypad 修正数字键区按键混淆问题 -L --nonewlines 不要将换行加到文件末端 -N --noconvert 不要从 DOS/Mac 格式转换 -O --morespace 编辑时多使用一行 -Q &lt;字符串&gt; --quotestr=&lt;字符串&gt; 引用代表字符串 -R --restricted 限制模式 -S --smooth 按行滚动而不是半屏 -T &lt;#列数&gt; --tabsize=&lt;#列数&gt; 设定制表符宽度为 #列数 -U --quickblank 状态行快速闪动 -V --version 显示版本资讯并离开 -W --wordbounds 更正确地侦测单字边界 -Y &lt;字符串&gt; --syntax=&lt;字符串&gt; 用于加亮的语法定义 -c --const 持续显示游标位置 -d --rebinddelete 修正退格键/删除键混淆问题 -i --autoindent 自动缩进新行 -k --cut 从游标剪切至行尾 -l --nofollow 不要依照符号连结，而是覆盖 -m --mouse 启用鼠标功能 -o &lt;目录&gt; --operatingdir=&lt;目录&gt; 设定操作目录 -p --preserve 保留XON (^Q) 和XOFF (^S) 按键 -q --quiet 沉默忽略启动问题, 比如rc 文件错误 -r &lt;#列数&gt; --fill=&lt;#列数&gt; 设定折行宽度为 #列数 -s &lt;程序&gt; --speller=&lt;程序&gt; 启用替代的拼写检查程序 -t --tempfile 离开时自动储存，不要提示 -u --undo 允许通用撤销[试验性特性] -v --view 查看(只读)模式 -w --nowrap 不要自动换行 -x --nohelp 不要显示辅助区 -z --suspend 启用暂停功能 -$ --softwrap 启用软换行 -a, -b, -e, -f, -g, -j (忽略，为与Pico 相容) 光标控制移动光标：使用用方向键移动。选择文字：按住鼠标左键拖到。 复制、剪贴和粘贴复制一整行：Alt+6剪贴一整行：Ctrl+K删除一整行：Ctrl+k 粘贴：Ctrl+U如果需要复制／剪贴多行或者一行中的一部分，先将光标移动到需要复制／剪贴的文本的开头，按Ctrl+6（或者Alt+A）做标记，然后移动光标到 待复制／剪贴的文本末尾。这时选定的文本会反白，用Alt+6来复制，Ctrl+K来剪贴。若在选择文本过程中要取消，只需要再按一次Ctrl+6。 搜索按Ctrl+W，然后输入你要搜索的关键字，回车确定。这将会定位到第一个匹配的文本，接着可以用Alt+W来定位到下一个匹配的文本。 翻页用Ctrl+Y到上一页，Ctrl+V到下一页 保存使用Ctrl+O来保存所做的修改 退出按Ctrl+X 如果你修改了文件，下面会询问你是否需要保存修改。输入Y确认保存，输入N不保存，按Ctrl+C取消返回。如果输入了Y，下一步会让你输入想要保存的文件名。如果不需要修改文件名直接回车就行；若想要保存成别的名字（也就是另存为）则输入新名称然后确 定。这个时候也可用Ctrl+C来取消返回。]]></content>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[virtualenvwrapper]]></title>
    <url>%2F2018%2F08%2F22%2F%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%2FPython%2Fvirtualenvwrapper%2F</url>
    <content type="text"><![CDATA[安装virtualenv 1sudo pip install virtualenv 安装virtualenvwrapper 1sudo pip install virtualenvwrapper 编译virtualenvwrapper.sh 1source /usr/local/bin/virtualenvwrapper.sh 设置WORKON_HOME，每次启动shell都生效 123456nano ~/.bashrcexport WORKON_HOME=$HOME/.virtualenvssource /usr/local/bin/virtualenvwrapper.shsource ~/.bashrc 创建虚拟环境 1mkvirtualenv py2env 进入虚拟环境 1workon py2env 退出虚拟环境 1deactivate]]></content>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell]]></title>
    <url>%2F2018%2F08%2F20%2FLinux%2Fshell%2F</url>
    <content type="text"><![CDATA[基础知识 shell标识#!/bin/bash#!告诉系统用后面指定路径中的程序来解释此脚本文件 运行方法 作为可执行程序 12chmod +x ./test.sh./test.sh 作为解释器参数 1bash test.sh 变量只读变量,不可修改12url='http://www.baidu.com'readonly url 删除变量1unset variable_name 字符串1234name="zong"echo "name:$&#123;name&#125;"echo "len:$&#123;#name&#125;"echo "substr:$&#123;name:1:3&#125;" 注释123:&lt;&lt;EOF注释内容...EOF 传递参数1234567891011121314151617181920212223242526#!/bin/bashecho 'shell 传递参数实例：'echo "执行文件名:$0"echo "第一个参数:$1" echo "第一个参数:$2" echo "第一个参数:$3" echo "共$#个参数"echo "所有参数:$*"echo "所有参数:$@"echo "脚本运行的当前进程ID:$$"echo "后台运行的最后一个进程的ID号:$!"echo "显示shell使用的当前选项:$-"echo "最后命令的退出状态码:$?"echo '$*和$@的区别:'echo '$*:'for i in "$*";do echo $&#123;i&#125;doneecho '$@:'for i in "$@";do echo $&#123;i&#125;done 数组1array=(val1 val2 val3 ...) 单独定义数组的各个分量：1array[2]=val2 读取数组1$&#123;array[1]&#125; 获取数组长度123$&#123;#array[*]&#125; or$&#123;#array[@]&#125; 基本运算符expr和awk123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101#!/bin/bash# 算术运算符val=`expr 2 + 2`echo $vala=10b=20echo "a:$a"echo "b:$b"val=`expr $a + $b`echo "a + b = $val"val=`expr $a - $b`echo "a - b = $val"val=`expr $a \* $b` # 乘法，*号前必须加斜杠echo "a * b = $val"val=`expr $b / $a`echo "b / a = $val"val=`expr $a % $b`echo "a % b = $val"if [ $a == $b ]then echo 'a == b'fiif [ $a != $b ]then echo 'a != b'fi# linux中的表达式： `expr 表达式`# mac中的表达式：$((表达式))echo $(($a + $b))# 关系运算符if [ $a -eq $b ]then echo 'a==b'fiif [ $a -ne $b ]then echo 'a!=b'fiif [ $a -gt $b ]then echo 'a&gt;b'fiif [ $a -lt $b ]then echo 'a&lt;b'fiif [ $a -ge $b ]then echo 'a&gt;=b'fiif [ $a -le $b ]then echo 'a&lt;=b'fi:&lt;&lt;EOF 布尔运算符 ! 非运算 [ !false ] true -o 或运算 [ $a -lt 20 -o $b -gt 100 ] true -a 与运算 [ $a -lt 20 -a $b -gt 100 ] falseEOF:&lt;&lt;EOF逻辑运算符&amp;&amp; [[ $a -lt 100 &amp;&amp; $b -gt 100 ]]|| [[ $a -lt 100 || $b -gt 100 ]]EOF# 字符串运算符:&lt;&lt;EOFa='abc'b='efg''a=b:' [ $a = $b ]'a!=b:' [ $a != $b ]'检测字符串长度是否为0:' [ -z $a ]'检测字符串长度是否不为0:' [ -n $a ]'检测字符串是否为空:' [ $a ]# 文件测试运算符'块设备:' [ -b $file ]'字符设备:' [ -c $file ]'目录:' [-d $file]'普通文件:' [ -f $file ]'是否是有名管道:' [ -p $file ]'读:' [ -r $file ]'写:' [ -w $file ]'执行:' [ -x $file ]'文件是否为空:' [ -s $file ]'检测文件（目录）是否存在：' [ -e $file ]EOF printf命令123456789printf '语法：printf format-string [args...]\n'format_str="%-10s %-8s %-4s\n"format_num="%-10s %-8s %-4.2f\n"printf "$format_str" 姓名 性别 体重Kgprintf "$format_num" 郭靖 男 66.1234printf "$format_num" 黄蓉 女 32.1234printf "$format_num" 杨过 男 65.1234printf "$format_num" 小龙女 女 35.1234 流程控制1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#!/bin/bash#if elsea=10if [ $a == 10 ]then echo $aelse echo 'no $a'fi# for循环for loop in 1 2 3 4 5do echo $loopdone# while循环i=0while((i&lt;10)); do let "i++" echo $&#123;i&#125;done# 无限循环:&lt;&lt;EOFwhile true; do echo 'loop'done或者for ((;;))EOF# util语句j=0until ((j&gt;10)); do let "j++" echo $&#123;j&#125;done# case语句echo '输入1到4之间的数字：'echo '你输入的数字为：'read numcase $num in 1) echo '你选择了1';; 2) echo '你选择了2';; 3) echo '你选择了3';; 4) echo '你选择了4';;esac# 跳出循环# break语句while true; do echo -n '输入1-5之间的数字' read num case $num in 1|2|3|4|5) echo "你输入了$num";; *) echo '你输入的不是1-5之间的数字，程序退出' break ;; esacdone#continue语句while true; do echo -n '输入1-5之间的数字' read num case $num in 1|2|3|4|5) echo "你输入了$num";; 0) echo '程序结束' break ;; *) echo '你输入的不是1-5之间的数字，程序退出' continue ;; esacdone 函数123456789101112131415161718192021#!/bin/bashconsole()&#123; echo 'console sth.' echo "参数:$1"&#125;echo '输出函数：'consoleconsole zongadd()&#123; echo '输入两个数进行加运算' echo '请输入第一个数:' read num1 echo '请输入第二个数:' read num2 return $(($num1+$num2))&#125;addecho "输入的两个数之和为：$?" 文件包含123. filename # 注意点号(.)和文件名中间有一个空格or source filename]]></content>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Express]]></title>
    <url>%2F2018%2F08%2F20%2F%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%2FNodejs%2Fexpress%2F</url>
    <content type="text"><![CDATA[安装 Express1cnpm install express --save 需要和express框架一起安装的模块： body-parsernode.js中间件，用于处理json,raw,text和url编码的数据。四种不同的处理方法：bodyParser.json(options) 处理json数据bodyParser.raw(options) Buffer流数据bodyParser.text(options) 文本数据bodyParser.urlencoded(options) UTF-8的编码数据 三种用法： 底层中间件用法：这将拦截和解析所有的请求；即全局的。 12345678910111213var express = require('express')var bodyParser = require('body-parser')var app = express()app.use(bodyParser.urlencoded(&#123;extended:false&#125;))app.use(bodyParser.json())//全局拦截app.use((req,res)=&gt;&#123; res.setHeader('Content-Type','text/plain') res.write('you posted:\n') res.end(JSON.stringify(req.body,null,2))&#125;) 特定路由下的中间件用法：对特定路由下的特定请求，只有请求该路由时，中间件才会拦截和解析该请求，即局部的，也是最常用的一个方式。 123456789101112131415161718var express = require('express')var bodyParser = require('body-parser')var app = express()// create application/json parservar jsonParser = bodyParser.json()// create application/x-www-form-urlencoded parservar urlencodedParser = bodyParser.urlencoded(&#123; extended: false &#125;)// POST /login gets urlencoded bodiesapp.post('/login', urlencodedParser, function (req, res) &#123; if (!req.body) return res.sendStatus(400) res.send('welcome, ' + req.body.username)&#125;)// POST /api/users gets JSON bodiesapp.post('/api/users', jsonParser, function (req, res) &#123; if (!req.body) return res.sendStatus(400) // create user in req.body&#125;) 设置Content-Type 属性；用于修改和设定中间件解析的body类容类型。 12345678// parse various different custom JSON types as JSONapp.use(bodyParser.json(&#123; type: 'application/*+json' &#125;); // parse some custom thing into a Bufferapp.use(bodyParser.raw(&#123; type: 'application/vnd.custom-type' &#125;)); // parse an HTML body into a stringapp.use(bodyParser.text(&#123; type: 'text/html' &#125;)); cookie-parser这就是一个解析Cookie的工具。通过req.cookies可以取到传过来的cookie，并把它们转成对象 multerexpress官方推荐的文件上传中间件 1cnpm install body-parser cookie-parser multer --save]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Node.js]]></title>
    <url>%2F2018%2F08%2F15%2F%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%2FNodejs%2FNodejs%2F</url>
    <content type="text"><![CDATA[交互式解释器下划线变量（_）,可以使用下划线获取上一个表达式的运算结果123456&gt; var x = 10&gt; var y = 20&gt; x + y&gt; var sum = _&gt; console.log(sum)30_ REPL命令12345678ctrl+c //退出当前终端ctrl+c //退出Node REPL 按下两次 ctrl+d //退出Node REPL.help //列出使用命令.break //退出多行表达式.clear //退出多行表达式.save &lt;filename&gt; //保存当前的Node REPL会话到指定文件.load &lt;filename&gt; //载入当前的Node REPL会话的文件内容 回调函数Node.js异步编程的直接体现就是回调。回调函数接收错误对象作为第一个参数。123$ touch input.txt$ nano input.txthello nodejs 阻塞代码实例1234var fs = require('fs');var data = fs.readFileSync('input.txt');console.log(data.toString());console.log('程序执行结束'); 输出12hello nodejs程序执行结束 程序顺序执行，读取文件阻塞 非阻塞代码实例123456var fs = require('fs');fs.readFile('input.txt',function(err,data)&#123; if(err)return console.log(err); console.log(data.toString());&#125;);console.log('程序执行结束'); 输出12程序执行结束hello nodejs 程序异步执行，文件读取完成后调用回调函数；后面的程序不会被阻塞。 事件1234567891011121314151617181920212223//引入events模块var events = require('events');//创建eventEmitter对象var eventEmitter = new events.EventEmitter();//创建连接事件处理程序var connectHandler = function connected()&#123; console.log('连接成功.'); //触发接收数据事件 eventEmitter.emit('data_received');&#125;//绑定connection事件处理程序eventEmitter.on('connection',connectHandler);//绑定接收数据事件eventEmitter.on('data_received',function()&#123; console.log('数据接收成功.')&#125;)//触发连接事件eventEmitter.emit('connection');console.log('程序执行完毕.'); EventEmitter类实例方法addListener(event,listener)为指定事件添加一个监听器到监听器数组的尾部 on(event,listener)为指定事件注册一个监听器，接收一个字符串event和一个回调函数。 once(event,listener)为指定事件注册一个单次监听器，即监听器最多只会触发一次，触发后立刻解除该监听器。 removeListener(event,listener)移除指定事件的某个监听器，监听器必须是该事件已经注册过的监听器。 removeAllListeners([event])移除所有事件的监听器，如果指定事件，则移除指定事件的所有监听器。 setMaxListeners(n)设置事件默认（10）允许的最大监听器数量。 listeners(event)返回指定事件的监听器数组。 emit(event,[arg1],[arg2],[…])按照参数的顺序执行每个监听器，如果事件又注册监听器返回true，否则返回false。 类方法listenerCount(emitter,event)返回指定事件的监听器数量。 实例事件newListener该事件在添加新监听器时被触发 event 字符串，事件名称 listener 处理事件函数 removeListener从指定监听器数组中删除一个监听器，此操作将会改变处于被删监听器后的那些监听器的索引。 event 字符串，事件名称 listener 处理事件函数 error事件EventEmitter类定义了一个特殊的事件error，包含了错误的语意。当error被触发时，如果没有响应的监听器，Node.js会把它当作异常，退出程序并输出错误信息。一般情况下需要为会触发error 事件的对象设置监听器，避免遇到错误后整个程序崩溃。123var events = require('events');var emitter = new events.EventEmitter();emitter.emit('error'); 继承EventEmitter大多数时候我们不会直接使用 EventEmitter，而是在对象中继承它。包括 fs、net、 http 在内的，只要是支持事件响应的核心模块都是 EventEmitter 的子类。为什么要这样做呢？原因有两点： 具有某个实体功能的对象实现事件符合语义， 事件的监听和发生应该是一个对象的方法。 JavaScript 的对象机制是基于原型的，支持 部分多重继承，继承 EventEmitter 不会打乱对象原有的继承关系。 Node.js Buffer（缓冲区） 在v6.0之前创建Buffer对象直接使用new Buffer()构造函数来创建对象实例，但是Buffer对内存的权限操作相比很大，可以直接捕获一些敏感信息，所以在v6.0以后，官方文档里面建议使用 Buffer.from() 接口去创建Buffer对象。 创建Buffer类Buffer 提供了以下 API 来创建 Buffer 类： Buffer.alloc(size[, fill[, encoding]])： 返回一个指定大小的 Buffer 实例，如果没有设置 fill，则默认填满 0 Buffer.allocUnsafe(size)： 返回一个指定大小的 Buffer 实例，但是它不会被初始化，所以它可能包含敏感的数据 Buffer.allocUnsafeSlow(size) Buffer.from(array)： 返回一个被 array 的值初始化的新的 Buffer 实例（传入的 array 的元素只能是数字，不然就会自动被 0 覆盖） Buffer.from(arrayBuffer[, byteOffset[, length]])： 返回一个新建的与给定的 ArrayBuffer 共享同一内存的 Buffer。 Buffer.from(buffer)： 复制传入的 Buffer 实例的数据，并返回一个新的 Buffer 实例 Buffer.from(string[, encoding])： 返回一个被 string 的值初始化的新的 Buffer 实例 写入缓冲区12buf.write(string[,offset[,length]][,encoding])返回值：返回实际写入的大小，如果buffer空间不足，则只会写入部分字符。 从缓冲区读取数据1buf.toString([encoding[,start[,end]]]) 返回值：解码缓冲区数据并使用指定的编码返回字符串。 将Buffer转换为JSON对象1buf.toJSON() 返回值：返回JSON对象 缓冲区合并1234Buffer.concat(list[,totalLength])参数： - list 用户合并的Buffer对象数组列表 - totalLength 指定合并后Buffer对象的总长度 缓冲区比较1buf.compare(otherBuffer); 拷贝缓冲区123456buf.copy(targetBuffer[,targetStart[,sourceStart[,sourceEnd]]])参数： - targetBuffer - 要拷贝的 Buffer 对象。 - targetStart - 数字, 可选, 默认: 0 - sourceStart - 数字, 可选, 默认: 0 - sourceEnd - 数字, 可选, 默认: buffer.length 缓冲区裁剪1buf.slice([start[,end]) 缓冲区长度1buf.length; Node.js Stream 流Stream四种流类型： Readable - 可读操作。 Writable - 可写操作。 Duplex - 可读可写操作. Transform - 操作被写入数据，然后读出结果。 所有的Stream对象都是EventEmitter的实例。常用的事件有： data - 当有数据可读时触发。 end - 没有更多的数据可读时触发。 error - 在接收和写入过程中发生错误时触发。 finish - 所有数据已被写入到底层系统时触发。 从流中读取数据1234567891011121314var fs = require('fs');var data = '';var readerStream = fs.createReadStream('input.txt');readerStream.setEncoding('UTF8');readerStream.on('data',function(chunk)&#123; data+=chunk;&#125;)readerStream.on('end',function()&#123; console.log(data);&#125;)readerStream.on('error',function(err)&#123; console.log(err.stack);&#125;)console.log('programing is end.'); 写入流123456789101112var fs = require('fs');var data = 'hello nodejs,i am stream.';var writeStream = fs.createWriteStream('output.txt');writeStream.write(data,'UTF8');writeStream.end();writeStream.on('finish',()=&gt;&#123; console.log('write finished.');&#125;)writeStream.on('error',(err)=&gt;&#123; console.log(err.stack);&#125;)console.log('programing end.'); 管道(pipe)实现大文件的复制。123456var fs = require('fs');var readerStream = fs.createReadStream('input.txt');var writeStream = fs.createWriteStream('output.txt');//管道操作readerStream.pipe(writeStream);console.log('program end.'); 链式流链式是通过连接输出流到另外一个流并创建多个流操作链的机制。链式流一般用于管道操作。接下来我们就是用管道和链式来压缩和解压文件。压缩文件123456var fs = require('fs');var zlib = require('zlib');var readerStream = fs.createReadStream('input.txt');var writeStream = fs.createWriteStream('input.txt.gz');readerStream.pipe(zlib.createGzip()).pipe(writeStream);console.log('program end.'); 解压文件123456var fs = require('fs');var zlib = require('zlib');var readerStream = fs.createReadStream('input.txt.gz');var writeStream = fs.createWriteStream('input1.txt');readerStream.pipe(zlib.createGunzip()).pipe(writeStream);console.log('program end.'); Node.js 路由server.js123456789101112var http = require('http');var url = require('url');const PORT = 3000;var start = function(route)&#123; var onRequest = function(request,response)&#123; var pathname = url.parse(request.url).pathname; route(pathname); &#125; http.createServer(onRequest).listen(PORT); console.log(`Server start http://localhost:$&#123;PORT&#125;`);&#125;exports.start = start; router.js1234var route = function(pathname)&#123; console.log(pathname);&#125;exports.route = route; index.js123var server = require('./server');var router = require('./router');server.start(router.route); Node.js Express 框架 模块系统模块系统的加载优先级 http模块安装1$ npm install http 使用123456789101112// 引入required模块var http = require("http");//创建服务器，接收请求与响应请求http.createServer(function(request,response)&#123; //发送HTTP头部 //HTTP状态值：200 ：OK //内容类型：text/plain response.writeHead(200,&#123;'Content-Type':'text/plain'&#125;); //发送响应数据 response.end('Hello World\n');&#125;).listen(8888) web框架模块express安装1234567891011$ npm install express //全局安装// 安装失败npm err! Error: connect ECONNREFUSED 127.0.0.1:8087// 解决办法$ npm config set proxy null// 卸载模块$ npm uninstall express// 更新模块$ npm update express// 搜索模块$ npm search express 使用1var express = require('express');]]></content>
      <tags>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客框架]]></title>
    <url>%2F2018%2F08%2F15%2F%E5%B7%A5%E5%85%B7%2FHexo%E5%8D%9A%E5%AE%A2%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[安装Hexo1$ npm install -g hexo-cli 建站123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install 新建文章如果没有设置layout的话，默认使用_config.yml中的default_layout参数代替。如果标题包含空格，需使用引号括起来。1$ hexo new [layout] &lt;title&gt; 生成静态文件1234$ hexo generate参数 -d, --deploy 文件生成后立即部署网站 -w, --watch 监视文件变动 该命令可以简写为1$ hexo g 发布1$ hexo publish [layout] &lt;filename&gt; 启动服务器123456$ hexo server默认情况下，访问网址为：`http://localhost:4000/`参数 -p, --port 重设端口 -s, --static 只使用静态文件 -l, --log 启动日记记录，使用覆盖记录格式 部署123$ hexo deploy参数 -g, --generate 部署之前预先生成静态文件 简写1$ hexo d 渲染文件123$ hexo render &lt;files&gt;[file2]...参数 -o,--output 设置输出路径 迁移1$ hexo migrate &lt;type&gt; 清除缓存1$ hexo clean 列出网站资料1$ hexo list &lt;type&gt; 显示Hexo版本1$ hexo version 使用主题next1$ git clone https://github.com/iissnan/hexo-theme-next themes/next]]></content>
      <tags>
        <tag>前端框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sublime Text3快捷键大全]]></title>
    <url>%2F2017%2F12%2F18%2F%E5%B7%A5%E5%85%B7%2FSublimeText3%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[基础命令123456789101112131415161718192021222324252627282930313233343536Ctrl+Shift+P：打开命令面板Ctrl+P：搜索项目中的文件Ctrl+G：跳转到第几行Ctrl+W：关闭当前打开文件Ctrl+Shift+W：关闭所有打开文件Ctrl+Shift+V：粘贴并格式化Ctrl+D：选择单词，重复可增加选择下一个相同的单词Ctrl+L：选择行，重复可依次增加选择下一行Ctrl+Shift+L：选择多行Ctrl+Shift+Enter：在当前行前插入新行Ctrl+X：删除当前行Ctrl+M：跳转到对应括号Ctrl+U：软撤销，撤销光标位置Ctrl+J：选择标签内容Ctrl+F：查找内容Ctrl+Shift+F：查找并替换Ctrl+H：替换Ctrl+R：前往 methodCtrl+N：新建窗口Ctrl+K+B：开关侧栏Ctrl+Shift+M：选中当前括号内容，重复可选着括号本身Ctrl+F2：设置/删除标记Ctrl+/：注释当前行Ctrl+Shift+/：当前位置插入注释Ctrl+Alt+/：块注释，并Focus到首行，写注释说明用的Ctrl+Shift+A：选择当前标签前后，修改标签用的F11：全屏Shift+F11：全屏免打扰模式，只编辑当前文件Alt+F3：选择所有相同的词Alt+.：闭合标签Alt+Shift+数字：分屏显示Alt+数字：切换打开第N个文件Shift+右键拖动：光标多不，用来更改或插入列内容鼠标的前进后退键可切换Tab文件按Ctrl，依次点击或选取，可需要编辑的多个位置按Ctrl+Shift+上下键，可替换行 选择类123456789101112131415161718192021222324252627282930313233343536373839404142434445Ctrl+D 选中光标所占的文本，继续操作则会选中下一个相同的文本。Alt+F3 选中文本按下快捷键，即可一次性选择全部的相同文本进行同时编辑。举个栗子：快速选中并更改所有相同的变量名、函数名等。Ctrl+L 选中整行，继续操作则继续选择下一行，效果和 Shift+↓ 效果一样。Ctrl+Shift+L 先选中多行，再按下快捷键，会在每行行尾插入光标，即可同时编辑这些行。Ctrl+Shift+M 选择括号内的内容（继续选择父括号）。举个栗子：快速选中删除函数中的代码，重写函数体代码或重写括号内里的内容。Ctrl+M 光标移动至括号内结束或开始的位置。Ctrl+Enter 在下一行插入新行。举个栗子：即使光标不在行尾，也能快速向下插入一行。Ctrl+Shift+Enter 在上一行插入新行。举个栗子：即使光标不在行首，也能快速向上插入一行。Ctrl+Shift+[ 选中代码，按下快捷键，折叠代码。Ctrl+Shift+] 选中代码，按下快捷键，展开代码。Ctrl+K+0 展开所有折叠代码。Ctrl+← 向左单位性地移动光标，快速移动光标。Ctrl+→ 向右单位性地移动光标，快速移动光标。shift+↑ 向上选中多行。shift+↓ 向下选中多行。Shift+← 向左选中文本。Shift+→ 向右选中文本。Ctrl+Shift+← 向左单位性地选中文本。Ctrl+Shift+→ 向右单位性地选中文本。Ctrl+Shift+↑ 将光标所在行和上一行代码互换（将光标所在行插入到上一行之前）。Ctrl+Shift+↓ 将光标所在行和下一行代码互换（将光标所在行插入到下一行之后）。Ctrl+Alt+↑ 向上添加多行光标，可同时编辑多行。Ctrl+Alt+↓ 向下添加多行光标，可同时编辑多行。 编辑类12345678910111213141516171819202122232425262728293031Ctrl+J 合并选中的多行代码为一行。举个栗子：将多行格式的CSS属性合并为一行。Ctrl+Shift+D 复制光标所在整行，插入到下一行。Tab 向右缩进。Shift+Tab 向左缩进。Ctrl+K+K 从光标处开始删除代码至行尾。Ctrl+Shift+K 删除整行。Ctrl+/ 注释单行。Ctrl+Shift+/ 注释多行。Ctrl+K+U 转换大写。Ctrl+K+L 转换小写。Ctrl+Z 撤销。Ctrl+Y 恢复撤销。Ctrl+U 软撤销，感觉和 Gtrl+Z 一样。Ctrl+F2 设置书签Ctrl+T 左右字母互换。F6 单词检测拼写 搜索类123456789101112131415Ctrl+F 打开底部搜索框，查找关键字。Ctrl+shift+F 在文件夹内查找，与普通编辑器不同的地方是sublime允许添加多个文件夹进行查找，略高端，未研究。Ctrl+P 打开搜索框。举个栗子：1、输入当前项目中的文件名，快速搜索文件，2、输入@和关键字，查找文件中函数名，3、输入：和数字，跳转到文件中该行代码，4、输入#和关键字，查找变量名。Ctrl+G 打开搜索框，自动带：，输入数字跳转到该行代码。举个栗子：在页面代码比较长的文件中快速定位。Ctrl+R 打开搜索框，自动带@，输入关键字，查找文件中的函数名。举个栗子：在函数较多的页面快速查找某个函数。Ctrl+： 打开搜索框，自动带#，输入关键字，查找文件中的变量名、属性名等。Ctrl+Shift+P 打开命令框。场景栗子：打开命名框，输入关键字，调用sublime text或插件的功能，例如使用package安装插件。Esc 退出光标多行选择，退出搜索框，命令框等。 显示类123456789101112131415161718192021222324Ctrl+Tab 按文件浏览过的顺序，切换当前窗口的标签页。Ctrl+PageDown 向左切换当前窗口的标签页。Ctrl+PageUp 向右切换当前窗口的标签页。Alt+Shift+1 窗口分屏，恢复默认1屏（非小键盘的数字）Alt+Shift+2 左右分屏-2列Alt+Shift+3 左右分屏-3列Alt+Shift+4 左右分屏-4列Alt+Shift+5 等分4屏Alt+Shift+8 垂直分屏-2屏Alt+Shift+9 垂直分屏-3屏Ctrl+K+B 开启/关闭侧边栏。F11 全屏模式Shift+F11 免打扰模式]]></content>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django REST FrameWork]]></title>
    <url>%2F2017%2F12%2F16%2F%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%2FPython%2FDjango%20REST%20FrameWork%2F</url>
    <content type="text"><![CDATA[配置要求REST framework有以下要求： Python(2.7,3.2,3.3,3.4,3.5) Django(1.7+,1.8,1.9) 可选的包： Markdown(2.1.0+) -为可视化API提供支持 django-filter(0.9.2+)-过滤支持 安装123pip install djangorestframeworkpip install markdownpip install django-filter 或者1git clone git@github.com:tomchristie/django-rest-framework.git 注册APP12345INSTALLED_APPS=( ..., &apos;snippets&apos;, &apos;rest_framework&apos;) 可视化API添加REST framework的登录/登出视图。在根urls.py文件中添加：1234urlpatterns = [ ..., url(r&apos;/api-auth&apos;,include(&apos;rest_framework.urls&apos;,namespace=&apos;rest_framework&apos;)] setting.py模块中：1234567REST_FRAMEWORK = &#123; # 使用Django的标准`django.contrib.auth`权限管理类, # 或者为尚未认证的用户，赋予只读权限. &apos;DEFAULT_PERMISSION_CLASSES&apos;: [ &apos;rest_framework.permissions.DjangoModelPermissionsOrAnonReadOnly&apos; ]&#125; 开始REST新建模型snippets/models.py1234567891011121314151617181920212223242526272829303132333435from django.db import modelsfrom pygments.lexers import get_all_lexersfrom pygments.styles import get_all_stylesLEXERS = [item for item in get_all_lexers() if item[1]]LANGUAGE_CHOICE = sorted([(item[1][0], item[0]) for item in LEXERS])STYLE_CHOICE = sorted([(item, item) for item in get_all_styles()])class Snippet(models.Model): created = models.DateTimeField(auto_now_add=True) owner = models.ForeignKey(to='auth.User', related_name='snippets') title = models.CharField(max_length=100, blank=True, default='') code = models.TextField() highlighted = models.TextField() linenos = models.BooleanField(default=False) language = models.CharField(choices=LANGUAGE_CHOICE, default='python', max_length=100) style = models.CharField(choices=STYLE_CHOICE, default='friendly', max_length=100) def save(self, *args, **kwargs): """ 使用pygments来创建高亮代码 """ from pygments.lexers import get_lexer_by_name from pygments.formatters.html import HtmlFormatter from pygments import highlight lexer = get_lexer_by_name(self.language) linenos = self.linenos and 'table' or False options = self.title and &#123;'title': self.title&#125; or &#123;&#125; formatter = HtmlFormatter(style=self.style, linenos=linenos, full=True, **options) self.highlighted = highlight(self.code, lexer, formatter) super(Snippet, self).save(*args, **kwargs) class Meta: ordering = ('created',) 序列化snippets/serializers.py12345678910from rest_framework import serializersfrom models import LANGUAGE_CHOICE, STYLE_CHOICE, Snippetclass SnippetModelSerializer(serializers.HyperlinkedModelSerializer): owner = serializers.ReadOnlyField(source='owner.username') highlight = serializers.HyperlinkedIdentityField(view_name='snippet-highlight', format='html') class Meta: model = Snippet fields = ('url', 'owner', 'highlight', 'title', 'code', 'linenos', 'language', 'style') 认证和权限snippets/permissions.py1234567891011121314# coding:UTF-8from rest_framework import permissionsclass IsOwnerOrReadOnly(permissions.BasePermission): """ 自定义权限，只有创建者才能编辑，其他用户只能查看 """ def has_object_permission(self, request, view, obj): if request.method in permissions.SAFE_METHODS: return True return obj.owner == request.user 视图snippets/views.py123456789101112131415161718192021222324from models import Snippetfrom rest_framework.decorators import detail_routefrom rest_framework import permissions, viewsetsfrom rest_framework.response import Responsefrom serializers import SnippetModelSerializerclass SnippetViewSet(viewsets.ModelViewSet): """ 提供list,create,retrieve,update,destory 额外添加highlight """ from snippets.permissions import IsOwnerOrReadOnly queryset = Snippet.objects.all() serializer_class = SnippetModelSerializer permission_classes = (permissions.IsAuthenticatedOrReadOnly, IsOwnerOrReadOnly) def perform_create(self, serializer): serializer.save(owner=self.request.user) @detail_route(renderer_classes=[renderers.StaticHTMLRenderer]) def highlight(self, request, *args, **kwargs): snippet = self.get_object() return Response(snippet.highlighted) 路由urls.py模块中1234567891011121314from snippets import viewsfrom rest_framework import routersfrom django.conf.urls import url, includefrom django.contrib import adminrouter = routers.DefaultRouter()router.register(r'userlist',views.UserViewSet)router.register(r'snippets',views.SnippetViewSet)urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^api/', include(router.urls)), url(r'^api-auth/', include('rest_framework.urls', namespace='rest_framework'))]]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Scrapy]]></title>
    <url>%2F2017%2F12%2F03%2F%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%2FPython%2Fscrapy%2F</url>
    <content type="text"><![CDATA[官方文档 Spiders通用爬虫(Generic Spider)Scrapy内置了一些通用的爬虫基类，你可以通过继承这些基类来快速构建自己的爬虫。这些内置爬虫基类提供了许多常用功能，比如：通过指定的规则，sitemaps或者xml/csv格式的feed文件爬取网站的链接。接下来的例子，假定你已经创建了scrapy项目，在items.py中申明TestItem类：12345import scrapyclass TestItem(scrapy.Item): id = scrapy.Field() name = scrapy.Field() description = scrapy.Field() CrawlSpider1class scrapy.spiders.CrawlSpider 这是爬取正规网站最常用的爬虫，它通过一系列的规则为跟踪网站链接提供方便的机制。对于特殊的网站或项目它或许不是最适合的，但对于常用的网站足矣。对于特殊的功能，你可以继承它，然后重载自定义部分即可，或者用它来实现你自己的爬虫。与从spider继承的属性（需要指定）不同的是，该类支持一个特殊的属性： rules Rule对象的一个或多个列表，每个Rule为爬取网站定义了明确的行为。Rules Objects将在后面的部分进行介绍。如果多个Rule匹配了同一个链接，只有第一个匹配生效，取决于它们在改属性中的顺序。 CrawlSpider还暴露了一个可重写的方法： parse_start_url(response) 这个方法将被start_urls的响应调用，它允许解析初始的responses,必须返回一个Item对象或一个Request对象，或者一个包含这2个对象的可迭代类型。 Crawling rules1class scrapy.spiders.Rule(link_extractor,callback=None,cb_kwargs=None,follow=None,process_links=None,process_request=None) link_extractor是一个Link Extractor对象，用于提取爬取到的页面中的链接。callback每个提取到的链接调用的函数或字符串，这个callback的第一个参数是链接的response，必须返回一个Item或Request对象。 注意：不能将parse作为callback，因为CrawlSpider使用parse作为它处理逻辑的默认方法，如果重写,crawl spider讲不能正常工作。 cb_kwargscallback的参数follow布尔类型，控制是否爬取页面中提取到的链接。如果没有callback，follow的默认值为True,否则默认Falseprocess_links功能类似callback，主要用于过滤process_request 被匹配本条Rule的request调用，必须返回一个request或者None CrawlSpider例子12345678910111213141516171819202122232425import scrapyfrom scrapy.spiders import CrawlSpider, Rulefrom scrapy.linkextractors import LinkExtractorclass MySpider(CrawlSpider): name = 'example.com' allowed_domains = ['example.com'] start_urls = ['http://www.example.com'] rules = ( # Extract links matching 'category.php' (but not matching 'subsection.php') # and follow links from them (since no callback means follow=True by default). Rule(LinkExtractor(allow=('category\.php', ), deny=('subsection\.php', ))), # Extract links matching 'item.php' and parse them with the spider's method parse_item Rule(LinkExtractor(allow=('item\.php', )), callback='parse_item'), ) def parse_item(self, response): self.logger.info('Hi, this is an item page! %s', response.url) item = scrapy.Item() item['id'] = response.xpath('//td[@id="item_id"]/text()').re(r'ID: (\d+)') item['name'] = response.xpath('//td[@id="item_name"]/text()').extract() item['description'] = response.xpath('//td[@id="item_description"]/text()').extract() return item 这个爬虫将爬取example.com的首页，收集category和item页面的链接，item页面的链接使用parse_item方法解析，每个response将使用xpath提取数据，并返回一个Item对象。 XMLFeedSpider1class scrapy.spiders.XMLFeedSpider XMLFeedSpider被设计用来通过迭代指定的节点解析xml格式的订阅内容。解析器可选：iternodes,xml和html。出于性能考虑，推荐使用iternodes，因为xml和html为了解析一次性生成了整个DOM。然而，当解析的XML标记有问题时，使用html作为解析器是不错的选择。通过设置以下类属性来设置解析器和标签名：iterator 字符串，定义解析器。 ‘iternodes’ 基于正则表达式的快速解析器,默认。 ‘html’ 使用Selector的解析器，将所有Dom加载进内存，然后通过Dom解析。 ‘xml’ 同html itertag 定义解析的节点1itertag = 'product' namespaces包含(prefix,uri)的列表，prefix和uri将会通过调用register_namespace()方法注册。然后，你就可以在itertag中通过命名空间指定节点.123class Spider(XMLFeedSpider): namespaces = [('n', 'http://www.sitemaps.org/schemas/sitemap/0.9')] itertag = 'n:url' 可重写的方法： adapt_response(response)在response到达spider中间件后，spider解析前，对response body进行修改,返回一个新的reponse或者原来的response parse_node(response, selector)被itertag匹配的nodes调用，接收node的response和Selector,这个方法是必须重写的，否则，spider将不能正常工作。返回一个Item对象或Request对象，或者包含它们的可迭代内容。 process_results(response, results)被spider返回的结果调用，用于处理返回至框架核心前的最后一次请求，比如：设置item的ID。它接收一个结果的列表和生成这些结果的response。它必须返回一个结果的列表。 XMLFeedSpider 例子：1234567891011121314151617from scrapy.spiders import XMLFeedSpiderfrom myproject.items import TestItemclass MySpider(XMLFeedSpider): name = 'example.com' allowed_domains = ['example.com'] start_urls = ['http://www.example.com/feed.xml'] iterator = 'iternodes' # This is actually unnecessary, since it's the default value itertag = 'item' def parse_node(self, response, node): self.logger.info('Hi, this is a &lt;%s&gt; node!: %s', self.itertag, ''.join(node.extract())) item = TestItem() item['id'] = node.xpath('@id').extract() item['name'] = node.xpath('name').extract() item['description'] = node.xpath('description').extract() spider下载start_urls中给定的feed文档，然后通过itertag标签迭代节点item，输出并存储随机数据到Item中。 CSVFeedSpider1class scrapy.spiders.CSVFeedSpider CSVFeedSpider和XMLFeedSpider很像，除了迭代的对象是rows而不是nodes。每个迭代过程中调用parse_row()。 delimiter 每个字段的分隔符，在CSV文件中默认是’,’ quotechar 包含每个字段的符号，在CSV中默认是’”‘ headers CSV文件的列名，一个列表[] parse_row(response,row) 接收一个reponse参数和一个字典(代表每一行，键是csv文件的列名)。 CSVFeedSpider也可重写adapt_response 和 process_results方法。 实例:12345678910111213141516171819from scrapy.spiders import CSVFeedSpiderfrom myproject.items import TestItemclass MySpider(CSVFeedSpider): name = 'example.com' allowed_domains = ['example.com'] start_urls = ['http://www.example.com/feed.csv'] delimiter = ';' quotechar = "'" headers = ['id', 'name', 'description'] def parse_row(self, response, row): self.logger.info('Hi, this is a row!: %r', row) item = TestItem() item['id'] = row['id'] item['name'] = row['name'] item['description'] = row['description'] return item SitemapSpider1class scrapy.spiders.SitemapSpider SitemapSpider允许你根据网站的sitemaps进行爬取内容。它支持嵌套的sitemaps和从robots.txt文件中发现sitemap。 sitemap_urls 一个指向sitemaps的列表，包含了爬虫将要爬取得urls，也可指向robots.txt文件，它将从中提取出sitemap的urls sitemap_rules 一个(regex,callback)的列表：regex: 从sitemaps中匹配urls的正则表达式，regex可以是字符串或编译的正则表达式对象。callback：字符串或可调用的函数 1sitemap_rules = [(&apos;/product/&apos;, &apos;parse_product&apos;)] 规则按顺序匹配，选择匹配到的第一个。如果省略该属性，sitemap_urls中的所有urls将被parse处理。 sitemap_follow 需要被跟踪的sitemap的正则表达式列表。仅对使用sitemap文件指向其他sitemap文件的站点有效。默认的所有站点将被followed。 sitemap_alternate_links 指定 alternate links是否应该被followed。alternate links是指向同一网站的不同语言链接,使用的同一个url标记。如：1234&lt;url&gt; &lt;loc&gt;http://example.com/&lt;/loc&gt; &lt;xhtml:link rel="alternate" hreflang="de" href="http://example.com/de"/&gt;&lt;/url&gt; 如果配置了sitemap_alternate_links，将会检测http://example.com/和http://example.com/de。如果sitemap_alternate_links 为disabled，将只会检测http://example.com/，默认为disabled。 例子：123456789//解析sitemaps中的所有urlfrom scrapy.spiders import SitemapSpiderclass MySpider(SitemapSpider): sitemap_urls = ['http://www.example.com/sitemap.xml'] def parse(self, response): pass # ... scrape item here ... 123456789101112131415//通过sitemap_rules分别指定不同的链接的解析from scrapy.spiders import SitemapSpiderclass MySpider(SitemapSpider): sitemap_urls = ['http://www.example.com/sitemap.xml'] sitemap_rules = [ ('/product/', 'parse_product'), ('/category/', 'parse_category'), ] def parse_product(self, response): pass # ... scrape product ... def parse_category(self, response): pass # ... scrape category ... 12345678910111213//通过robots.txt文件跟踪sitemaps，并且只跟踪包含/sitemap_shop的链接from scrapy.spiders import SitemapSpiderclass MySpider(SitemapSpider): sitemap_urls = ['http://www.example.com/robots.txt'] sitemap_rules = [ ('/shop/', 'parse_shop'), ] sitemap_follow = ['/sitemap_shops'] def parse_shop(self, response): pass # ... scrape shop here ... 结合SitemapSpider和其他的urls1234567891011121314151617181920from scrapy.spiders import SitemapSpiderclass MySpider(SitemapSpider): sitemap_urls = ['http://www.example.com/robots.txt'] sitemap_rules = [ ('/shop/', 'parse_shop'), ] other_urls = ['http://www.example.com/about'] def start_requests(self): requests = list(super(MySpider, self).start_requests()) requests += [scrapy.Request(x, self.parse_other) for x in self.other_urls] return requests def parse_shop(self, response): pass # ... scrape shop here ... def parse_other(self, response): pass # ... scrape other here ... Selectors当你爬取网站页面的时候，最常见的事情就是从html中提取数据。下面介绍几个这方面的库： BeautifulSoup 在python开发者中非常流行的爬虫库，通过html结构创建python对象，能够合理的处理坏标签。但是它有一个缺点：慢。 lxml xml解析库，也能解析html，通过一个pythonic的API：ElementTree。lxml不是python标准库的一部分。 Scrapy有自己的提取数据的机制，被称为selectors，因为它通过XPath或CSS表达式选择HTML中指定部分。 XPath是一重在XML文档中选择nodes的语言，也能够用于html。CSS是应用于html样式的语言。它定义selectors关联到那些指定样式的html元素。 Scrapy selectors是建立在lxml库上的，这意味着它们在速度和解析准确度上非常相似。 下面介绍selectors是如何工作的，以及描述它小而简单的API，不同于lxml API，lxml API非常大，因为它被用来实现很多任务，不仅仅是选择文档标记。 完整的Selector参考 使用Selectors构建SelectorsScrapy selectors是Selector类的实例，通过传入text或TextResponse对象生成。它根据输入的类型自动选择最合适的解析规则（XML vs HTML）。12345678910&gt;&gt;from scrapy.selector import Selector&gt;&gt;from scrapy.http import HtmlResponse//通过text构建&gt;&gt;body = '&lt;html&gt;&lt;body&gt;&lt;span&gt;good&lt;/span&gt;&lt;/body&gt;&lt;/html&gt;'&gt;&gt;Selector(text=body).xpath('//span/text()').extract()[u'good']//从response构建&gt;&gt;response = HtmlResponse(url='http://example.com',body=body)&gt;&gt;Selector(response=response).xpath('//span/text()').extract()[u'good] 为了更便捷，response暴露了一个属性.selector，完全等价于上面的操作：1response.selector.xpath('//span/text()').extract() 使用为了解释怎么使用selectors，我们接下来将使用Scrapy shell和Scrapy服务器上的页面做实验：官网链接 HTML文档内容：123456789101112131415&lt;html&gt; &lt;head&gt; &lt;base href='http://example.com/' /&gt; &lt;title&gt;Example website&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div id='images'&gt; &lt;a href='image1.html'&gt;Name: My image 1 &lt;br /&gt;&lt;img src='image1_thumb.jpg' /&gt;&lt;/a&gt; &lt;a href='image2.html'&gt;Name: My image 2 &lt;br /&gt;&lt;img src='image2_thumb.jpg' /&gt;&lt;/a&gt; &lt;a href='image3.html'&gt;Name: My image 3 &lt;br /&gt;&lt;img src='image3_thumb.jpg' /&gt;&lt;/a&gt; &lt;a href='image4.html'&gt;Name: My image 4 &lt;br /&gt;&lt;img src='image4_thumb.jpg' /&gt;&lt;/a&gt; &lt;a href='image5.html'&gt;Name: My image 5 &lt;br /&gt;&lt;img src='image5_thumb.jpg' /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 首先，打开shell1scrapy shell http://doc.scrapy.org/en/latest/_static/selectors-sample1.html 然后，等待加载完成，你可以通过response变量获取响应结果，并且包含了response.selector属性。因为我们处理的HTML，选择器自动使用HTML parser。查看HTML页面代码，让我们一起构建一个XPath来获取title标记中的文本：12&gt;&gt;&gt; response.selector.xpath('//title/text()')[&lt;Selector (text) xpath=//title/text()&gt;] 因为查询响应使用XPath和CSS太常用了，所以reponses提供了2个便利的方式：response.xpath() 和 response.css():1234&gt;&gt;&gt; response.xpath('//title/text()')[&lt;Selector (text) xpath=//title/text()&gt;]&gt;&gt;&gt; response.css('title::text')[&lt;Selector (text) xpath=//title/text()&gt;] 如你所见，.xpath()和.css()方法返回一个selector实例的列表，使用这个API可以快速的选择嵌套的数据。123456&gt;&gt;&gt; response.css('img').xpath('@src').extract()[u'image1_thumb.jpg', u'image2_thumb.jpg', u'image3_thumb.jpg', u'image4_thumb.jpg', u'image5_thumb.jpg'] 提取文本数据，你必须使用.extract()方法，如下：12&gt;&gt;&gt; response.xpath('//title/text()').extract()[u'Example website'] 如果你只是想提取匹配到的第一个元素，可以使用.extract_first()12&gt;&gt;&gt; response.xpath('//div[@id="images"]/a/text()').extract_first()u'Name: My image 1 ' 如果没有找到元素将返回None,可通过传递一个参数来设置默认值取代None：12&gt;&gt;&gt; response.xpath('//div[@id="not-exists"]/text()').extract_first(default='not-found')'not-found' css选择器可以使用css3的伪类元素来选择文本：12&gt;&gt;&gt; response.css('title::text').extract()[u'Example website'] 现在我们将获取基本的URL和一些图片链接：123456789101112131415161718192021222324252627282930313233&gt;&gt;&gt; response.xpath('//base/@href').extract()[u'http://example.com/']&gt;&gt;&gt; response.css('base::attr(href)').extract()[u'http://example.com/']&gt;&gt;&gt; response.xpath('//a[contains(@href, "image")]/@href').extract()[u'image1.html', u'image2.html', u'image3.html', u'image4.html', u'image5.html']&gt;&gt;&gt; response.css('a[href*=image]::attr(href)').extract()[u'image1.html', u'image2.html', u'image3.html', u'image4.html', u'image5.html']&gt;&gt;&gt; response.xpath('//a[contains(@href, "image")]/img/@src').extract()[u'image1_thumb.jpg', u'image2_thumb.jpg', u'image3_thumb.jpg', u'image4_thumb.jpg', u'image5_thumb.jpg']&gt;&gt;&gt; response.css('a[href*=image] img::attr(src)').extract()[u'image1_thumb.jpg', u'image2_thumb.jpg', u'image3_thumb.jpg', u'image4_thumb.jpg', u'image5_thumb.jpg'] 嵌套选择器.xpath()和.css()返回一些相同类型的selectors，因此你能为这些selectors调用selection的方法。1234567891011121314151617&gt;&gt;&gt; links = response.xpath('//a[contains(@href, "image")]')&gt;&gt;&gt; links.extract()[u'&lt;a href="image1.html"&gt;Name: My image 1 &lt;br&gt;&lt;img src="image1_thumb.jpg"&gt;&lt;/a&gt;', u'&lt;a href="image2.html"&gt;Name: My image 2 &lt;br&gt;&lt;img src="image2_thumb.jpg"&gt;&lt;/a&gt;', u'&lt;a href="image3.html"&gt;Name: My image 3 &lt;br&gt;&lt;img src="image3_thumb.jpg"&gt;&lt;/a&gt;', u'&lt;a href="image4.html"&gt;Name: My image 4 &lt;br&gt;&lt;img src="image4_thumb.jpg"&gt;&lt;/a&gt;', u'&lt;a href="image5.html"&gt;Name: My image 5 &lt;br&gt;&lt;img src="image5_thumb.jpg"&gt;&lt;/a&gt;']&gt;&gt;&gt; for index, link in enumerate(links):... args = (index, link.xpath('@href').extract(), link.xpath('img/@src').extract())... print 'Link number %d points to url %s and image %s' % argsLink number 0 points to url [u'image1.html'] and image [u'image1_thumb.jpg']Link number 1 points to url [u'image2.html'] and image [u'image2_thumb.jpg']Link number 2 points to url [u'image3.html'] and image [u'image3_thumb.jpg']Link number 3 points to url [u'image4.html'] and image [u'image4_thumb.jpg']Link number 4 points to url [u'image5.html'] and image [u'image5_thumb.jpg'] 使用带正则表达式的选择器Selector还有一个.re()方法，用于使用正则表达式提取数据。然而，不像.xpath()或.css()方法，.re()返回一个unicode字符串的列表。所以.re()不能嵌套。 从上面的html代码中提取图片名称：123456&gt; response.xpath('//a[contains(@href, "image")]/text()').re(r'Name:\s*(.*)')[u'My image 1', u'My image 2', u'My image 3', u'My image 4', u'My image 5'] 提取匹配的第一个字符串：.re_first()12&gt;&gt;&gt; response.xpath(&apos;//a[contains(@href, &quot;image&quot;)]/text()&apos;).re_first(r&apos;Name:\s*(.*)&apos;)u&apos;My image 1&apos; 使用相对路径的XPaths如果你使用’/‘开头的XPath进行嵌套选择，那么XPath将是相对于文档的绝对路径，而不是上一层选择器的路径。比如，你想选择出所有div下的p元素：1&gt;&gt; divs = response.xpath('//div') 接下来，你可能想这样提取p元素：1&gt;&gt;[p.extract() for p in div.xpath('//p')] 但是，这是错误的，这样将提取到所有的p元素。应该这样来写：1&gt;&gt; [p.extract() for p in div.xpath('.//p')] 更多关于XPath相对路径的资料 XPath表达式中的变量XPath允许在表达式中使用变量，语法：$var。下面通过id属性的值来匹配元素，没有硬编码。12&gt;&gt; response.xpath('//div[@id=$val]/a/text()',val='images').extract_first()u'Name: My image 1' 另外一个例子：查找含有5个a标签的div的id12&gt;&gt; response.xpath('//div[count(a)=$cnt]/@id',cnt=5).extract_first()u'images' 所有引用的变量都必须赋值，不然xpath将报错。更多关于XPath Variable 使用EXSLT扩展 建立在lxml上，Scrapy选择器也支持EXSLT扩展，内置了一些预先注册好的命名空间可以在XPath表达式中使用。 prefix namespace usage re http://exslt.org/regular-expressions regular expressions set http://exslt.org/sets set manipulation 正则表达式 当XPath的starts-with()或contains()不够用的时候，test()函数将会非常有用。例如:从class以数字结尾的list的元素下提取链接。1234567891011121314151617&gt;&gt;from scrapy import Selector&gt;&gt; doc = """... &lt;div&gt;... &lt;ul&gt;... &lt;li class="item-0"&gt;&lt;a href="link1.html"&gt;first item&lt;/a&gt;&lt;/li&gt;... &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt;... &lt;li class="item-inactive"&gt;&lt;a href="link3.html"&gt;third item&lt;/a&gt;&lt;/li&gt;... &lt;li class="item-1"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt;... &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt;... &lt;/ul&gt;... &lt;/div&gt;... """&gt;&gt; sel = Selector(text=doc,type='html')&gt;&gt; sel.xpath('//li//a/@href').extract()[u'link1.html', u'link2.html', u'link3.html', u'link4.html', u'link5.html']&gt;&gt; sel.xpath('//li[re:test(@class,"item-\d$")]//@href').extract()[u'link1.html', u'link2.html', u'link4.html', u'link5.html'] 设置操作可以方便的在提取文本元素前排除部分dom元素。例如提取item的范围和相对应的属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&gt;&gt;&gt; doc = """... &lt;div itemscope itemtype="http://schema.org/Product"&gt;... &lt;span itemprop="name"&gt;Kenmore White 17" Microwave&lt;/span&gt;... &lt;img src="kenmore-microwave-17in.jpg" alt='Kenmore 17" Microwave' /&gt;... &lt;div itemprop="aggregateRating"... itemscope itemtype="http://schema.org/AggregateRating"&gt;... Rated &lt;span itemprop="ratingValue"&gt;3.5&lt;/span&gt;/5... based on &lt;span itemprop="reviewCount"&gt;11&lt;/span&gt; customer reviews... &lt;/div&gt;...... &lt;div itemprop="offers" itemscope itemtype="http://schema.org/Offer"&gt;... &lt;span itemprop="price"&gt;$55.00&lt;/span&gt;... &lt;link itemprop="availability" href="http://schema.org/InStock" /&gt;In stock... &lt;/div&gt;...... Product description:... &lt;span itemprop="description"&gt;0.7 cubic feet countertop microwave.... Has six preset cooking categories and convenience features like... Add-A-Minute and Child Lock.&lt;/span&gt;...... Customer reviews:...... &lt;div itemprop="review" itemscope itemtype="http://schema.org/Review"&gt;... &lt;span itemprop="name"&gt;Not a happy camper&lt;/span&gt; -... by &lt;span itemprop="author"&gt;Ellie&lt;/span&gt;,... &lt;meta itemprop="datePublished" content="2011-04-01"&gt;April 1, 2011... &lt;div itemprop="reviewRating" itemscope itemtype="http://schema.org/Rating"&gt;... &lt;meta itemprop="worstRating" content = "1"&gt;... &lt;span itemprop="ratingValue"&gt;1&lt;/span&gt;/... &lt;span itemprop="bestRating"&gt;5&lt;/span&gt;stars... &lt;/div&gt;... &lt;span itemprop="description"&gt;The lamp burned out and now I have to replace... it. &lt;/span&gt;... &lt;/div&gt;...... &lt;div itemprop="review" itemscope itemtype="http://schema.org/Review"&gt;... &lt;span itemprop="name"&gt;Value purchase&lt;/span&gt; -... by &lt;span itemprop="author"&gt;Lucas&lt;/span&gt;,... &lt;meta itemprop="datePublished" content="2011-03-25"&gt;March 25, 2011... &lt;div itemprop="reviewRating" itemscope itemtype="http://schema.org/Rating"&gt;... &lt;meta itemprop="worstRating" content = "1"/&gt;... &lt;span itemprop="ratingValue"&gt;4&lt;/span&gt;/... &lt;span itemprop="bestRating"&gt;5&lt;/span&gt;stars... &lt;/div&gt;... &lt;span itemprop="description"&gt;Great microwave for the price. It is small and... fits in my apartment.&lt;/span&gt;... &lt;/div&gt;... ...... &lt;/div&gt;... """&gt;&gt;&gt; sel = Selector(text=doc, type="html")&gt;&gt;&gt; for scope in sel.xpath('//div[@itemscope]'):... print "current scope:", scope.xpath('@itemtype').extract()... props = scope.xpath('''... set:difference(./descendant::*/@itemprop,... .//*[@itemscope]/*/@itemprop)''')... print " properties:", props.extract()... printcurrent scope: [u'http://schema.org/Product'] properties: [u'name', u'aggregateRating', u'offers', u'description', u'review', u'review']current scope: [u'http://schema.org/AggregateRating'] properties: [u'ratingValue', u'reviewCount']current scope: [u'http://schema.org/Offer'] properties: [u'price', u'availability']current scope: [u'http://schema.org/Review'] properties: [u'name', u'author', u'datePublished', u'reviewRating', u'description']current scope: [u'http://schema.org/Rating'] properties: [u'worstRating', u'ratingValue', u'bestRating']current scope: [u'http://schema.org/Review'] properties: [u'name', u'author', u'datePublished', u'reviewRating', u'description']current scope: [u'http://schema.org/Rating'] properties: [u'worstRating', u'ratingValue', u'bestRating']&gt;&gt;&gt; 首先，遍历了itemscope元素，针对每个itemscope查找itemprops并排除那些包含在其他itemscop中的itemprops。 关于XPath的一些建议一篇来自ScrapingHub的博客XPath文档 使用text节点的时候需要注意，当你将text内容作为参数传递给XPath string function时，避免使用.//text()，用.代替即可。因为表达式.//text()产生一个text元素的集合node-set,当node-set转换为string的时候，比如传递给contains()或starts-width()，将导致只会传递第一个元素的值。123456&gt;&gt;&gt; from scrapy import Selector&gt;&gt;&gt; sel = Selector(text='&lt;a href="#"&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;')&gt;&gt;&gt; sel.xpath('//a//text()').extract() # take a peek at the node-set[u'Click here to go to the ', u'Next Page']&gt;&gt;&gt; sel.xpath("string(//a[1]//text())").extract() # convert it to string[u'Click here to go to the '] 将一个node节点转换为string,将提取出该节点下的所有text1234&gt;&gt;&gt; sel.xpath("//a[1]").extract() # select the first node[u'&lt;a href="#"&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;']&gt;&gt;&gt; sel.xpath("string(//a[1])").extract() # convert it to string[u'Click here to go to the Next Page'] 所以，选择含有Next Page文本的a标签，如果这样写：12&gt;&gt; sel.xpath("//a[contains(.//text(),'Next Page')]").extract()[] 将不会有任何输出，因为原意是想先获取a的所有文本，然后检测是否包含’Next Page’,但是此处的.//text()转换为string只会输出[u’Click here to go to the ‘],并不包含’Next Page’。所以，应该这样写：12&gt;&gt; sel.xpath("//a[contains(.,'Next Page')]").extract()[u'&lt;a href="#"&gt;Click here to go to the &lt;strong&gt;Next Page&lt;/strong&gt;&lt;/a&gt;'] 注意区分 //node[1] 和 (//node)[1]//node[1]选择所有匹配节点各自父节点的第一个子节点(//node)[1]选择文档中的所有匹配节点，然后返回第一个例：123456789101112131415161718192021&gt;&gt;&gt; from scrapy import Selector&gt;&gt;&gt; sel = Selector(text="""....: &lt;ul class="list"&gt;....: &lt;li&gt;1&lt;/li&gt;....: &lt;li&gt;2&lt;/li&gt;....: &lt;li&gt;3&lt;/li&gt;....: &lt;/ul&gt;....: &lt;ul class="list"&gt;....: &lt;li&gt;4&lt;/li&gt;....: &lt;li&gt;5&lt;/li&gt;....: &lt;li&gt;6&lt;/li&gt;....: &lt;/ul&gt;""")&gt;&gt;&gt; xp = lambda x: sel.xpath(x).extract()&gt;&gt;&gt; xp("//li[1]")[u'&lt;li&gt;1&lt;/li&gt;', u'&lt;li&gt;4&lt;/li&gt;']&gt;&gt;&gt; xp("(//li)[1]")[u'&lt;li&gt;1&lt;/li&gt;']&gt;&gt;&gt; xp("//ul/li[1]")[u'&lt;li&gt;1&lt;/li&gt;', u'&lt;li&gt;4&lt;/li&gt;']&gt;&gt;&gt; xp("(//ul/li)[1]")[u'&lt;li&gt;1&lt;/li&gt;'] 使用class查询时，考虑使用CSS因为一个元素能够包含多个css，XPath选择元素相对css来说是很冗长的：1*[contains(concat(' ', normalize-space(@class), ' '), ' someclass ')] 如果你使用@class=&#39;someclass&#39;，将会丢失许多含有其他class的元素，如果使用contains(@class,&#39;someclass&#39;)，将有可能包含多余的class含有someclass子字符串的元素。Scrapy允许链式调用selectors，所以你可以先用css选择然后再用xpath。1234&gt;&gt;&gt; from scrapy import Selector&gt;&gt;&gt; sel = Selector(text='&lt;div class="hero shout"&gt;&lt;time datetime="2014-07-23 19:00"&gt;Special date&lt;/time&gt;&lt;/div&gt;')&gt;&gt;&gt; sel.css('.shout').xpath('./time/@datetime').extract()[u'2014-07-23 19:00'] 内置的Selectors参考Selector 对象1class scrapy.selector.Selector(response=None,text=None,type=None) Selector的实例是包装在response上用于提取指定的内容。response:一个 HtmlResponse或XmlResponse对象，用于选择和导出数据。text:unicode字符串或utf-8编码的文本，当response不存在的情况下。同时使用text和response是不可行的。type:定义选择器类型:”html”，”xml”或”None”(默认) 如果type为None时，选择器自动根据response选择最合适的类型，或如果类型为text时将默认为&quot;html&quot;。如果type为None，传递了response，选择器类型将从response类型中推算： &quot;html&quot;：HtmlResponse &quot;xml&quot;：XmlResponse &quot;html&quot;：anything 否则，如果type设定了，选择器类型将被强制指定为type，不再进行检测。 xpath(query) css(query) extract() re(regex) register_namespace(prefix,url) remove_namespaces() nonzero()是否选中内容 SelectorList objects1class scrapy.selector.SelectorList SelectorList类是list的一个子类，提供了一些附加的方法。 xpath(query) css(query) extract() re() 基于HTML Response的Selector例子假定sel是用一个HtmlResponse实例化的Selector1234567sel = Selector(html_response)sel.xpath("//h1")sel.xpath("//h1").extract() # includes h1sel.xpath("//h1/text()").extract() # excludes h1# 遍历所有的p标签，打印它们的类属性for node in sel.xpath("//p"): print node.xpath("@class").extract() 基于XML Response的Selector例子假设sel是用XmlResponse实例化的Selector12sel = Selector(xml_response)sel.xpath("//product") 从指定文档提取所有价格，需要使用命名空间：12sel.register_namespace("g","http://base.google.com/ns/1.0")sel.xpath("//g:price").extract() 移除命名空间 在Scrapy项目中，为了写更多简单便捷的XPaths,经常需要移除命名空间，仅剩元素名称。Selector.remove_namespaces() 12345678910&gt;&gt; scrapy shell https://github.com/blog.atom&gt;&gt; response.xpath("//link")[]# 因为Atom XML命名空间扰乱了节点&gt;&gt;&gt; response.selector.remove_namespaces()&gt;&gt;&gt; response.xpath("//link")[&lt;Selector xpath='//link' data=u'&lt;link xmlns="http://www.w3.org/2005/Atom'&gt;, &lt;Selector xpath='//link' data=u'&lt;link xmlns="http://www.w3.org/2005/Atom'&gt;, ...] 不默认移除命名空间的原因有二： 移除命名空间需要遍历所有的文档，对于爬虫来说这是一个相当费时且昂贵的操作。 有些时候需要使用命名空间来避免名称冲突。 Items声明Itmes使用class和Field对象来声明一个Item，如下所示：1234567import scrapyClass Product(scrapy.Item): name = scrapy.Field() price = scrapy.Field() stock = scrapy.Field() last_updated = scrapy.Field(serializer=str) 注意：Scrapy中的Items定义和Django中Models定义很像，不同的是Items中没有多种字段类型，只有简单的`scrapy.Field` Item FieldsField对象为每个字段指定metadata，例如上例中last_updated字段的serializer方法。 可以为每个字段指定任何类型的metadata,Field对象并没有限制接收的values，所以，这里并没有列出所有的metadata keys。在Field对象中定义的每个字段对应不同的功能，你也可以根据你的需要定义别的字段。Field对象的主要目标是提供一种在一个地方定义所有元数据(metadata)的方法。你可以查阅相关文档来使用metadata。 值得注意的是Field对象用来声明item字段的时候，该字段并不是作为类的属性，相反，可以通过Item.fields(此处Item对应Product)属性来访问。(类似dict而不是object) 使用Items这里有一些使用items的通用案例，使用上面声明的Product，你将会发现API非常类似dict API 创建items123&gt;&gt;&gt; product = Product(name='Desktop PC',price=1000)&gt;&gt;&gt; print productProduct(name='Desktop PC',price=1000) 获取字段值1234567891011121314151617181920212223242526&gt;&gt; product['name']Desktop PC&gt;&gt;&gt; product.get('name')Desktop PC&gt;&gt;&gt; product['price']1000&gt;&gt;&gt; product['last_updated']Traceback (most recent call last): ...KeyError: 'last_updated'&gt;&gt;&gt; product.get('last_updated', 'not set')not set&gt;&gt;&gt; product['lala'] # getting unknown fieldTraceback (most recent call last): ...KeyError: 'lala'&gt;&gt;&gt; product.get('lala', 'unknown field')'unknown field'&gt;&gt;&gt; 'name' in product # is name field populated?True&gt;&gt;&gt; 'last_updated' in product # is last_updated populated?False&gt;&gt;&gt; 'last_updated' in product.fields # is last_updated a declared field?True&gt;&gt;&gt; 'lala' in product.fields # is lala a declared field?False 设置字段值12345678&gt;&gt;&gt; product['last_updated'] = 'today'&gt;&gt;&gt; product['last_updated']today&gt;&gt;&gt; product['lala'] = 'test' # setting unknown fieldTraceback (most recent call last): ...KeyError: 'Product does not support field: lala' 访问所有值类似使用字典的API12345&gt;&gt;&gt; product.keys()['price','name']&gt;&gt;&gt; product.items()[('price', 1000), ('name', 'Desktop PC')] 其他通用的任务复制items1234567&gt;&gt;&gt; product2 = Product(product)&gt;&gt;&gt; print product2Product(name='Desktop PC', price=1000)&gt;&gt;&gt; product3 = product2.copy()&gt;&gt;&gt; print product3Product(name='Desktop PC', price=1000) items to dicts12&gt;&gt;&gt; dict(product) # create a dict from all populated values&#123;'price': 1000, 'name': 'Desktop PC'&#125; dicts to items1234567&gt;&gt;&gt; Product(&#123;'name': 'Laptop PC', 'price': 1500&#125;)Product(price=1500, name='Laptop PC')&gt;&gt;&gt; Product(&#123;'name': 'Laptop PC', 'lala': 1500&#125;) # warning: unknown field in dictTraceback (most recent call last): ...KeyError: 'Product does not support field: lala' 扩展Items可以通过继承Item来创建新的Item,以便增加字段或改变某些字段的信息。123class DiscountedProduct(Product): discount_percent = scrapy.Field(serializer=str) discount_expiration_date = scrapy.Field() 你也可以使用前面定义的字段元数据来扩展字段元数据，添加或改变原来的值。12class SpecificProduct(Product): name = scrapy.Field(Product.fields['name'], serializer=my_serializer) 此处扩展了Product的name字段的元数据，并在原来的基础上增加了serializer元数据。 Item对象class scrapy.item.Item([arg]) 从所给的参数中返回一个可选的初始化Item。 Items复制了标准的dict API,包括它的构造函数。只是添加了fields属性。 &gt; fields 包含了所有声明字段的字典。字段的名称作为键，声明的`Field`对象作为值。 Field对象class scrapy.item.Field([arg]) Field类只是内置dict类的一个别名，没有提供任何额外的功能或属性。换句话说Field只是普通的Python字典。一个单独用类属性来声明Item的类。 Item LoadersItem Loaders为构建scraped Itmes提供了便捷的途径。即使能够使用Item的类字典API来构建，但是Item Loaders在爬取过程中提供了许多便捷的API来构建items，通过一些自动化的通用任务，比如:在分发之前解析原始提取到的数据。 换句话说，Items为爬取到的数据提供容器，而Item Loaders提供便捷的途径来构造这个容器。 Item Loaders被设计为灵活、高效和简单的机制来扩展和覆盖不同字段的解析规则，无论是爬虫还是源格式(HTML，XML)维护起来都很方便。 使用Item Loaders来构建Items使用Item Loader前需要先实例化，你可以使用类字典(Item或者dict)或Item Loader构造器使用ItemLoader.default_item_class指定的属性来自动实例化Item。 然后，开始收集数据到Item Loader，通常使用Selectors。你可以添加多个值到相同的item字段，Item Loader会用合适的方法来处理。 这里有一个经典的Item Loader使用案例，使用前面章节定义的Product Item:1234567891011from scrapy.loader import ItemLoaderfrom myproject.items import Productdef parse(self,response): l = ItemLoader(item=Product(),response=response) l.add_xpath('name','//div[@class="product_name"]') l.add_xpath('name','//div[@class="product_title"]') l.add_xpath('price','//p[@id="price"]') l.add_css('stock','p#stock') l.add_value('last_updated','today') return l.load_item() 从上面的代码可以看到，name字段从不同的页面提取了2次：1.//div[@class=&quot;product_name&quot;]2.//div[@class=&quot;product_title&quot;] 换句话说，被指定给name字段的数据通过add_xpath()方法从2个XPath路径提取。 然后，同样的方法添加price和stock(stock使用CSS选择器add_css()方法添加)，最后用add_value直接给last_updated赋值’today’。 最后，当所有数据收集完成，ItemLoader.load_item()方法被调用，并返回用前面的add_xpath(),add_css(),add_value()提取的数据填充的item。 输入输出处理每个Item Loader为每个Item 字段都有一个输入处理器和一个输出处理器。输入处理器在收到数据的时候通过add_xpath(),add_css(),add_value()方法尽快提取数据，输入处理器的处理结果将被收集并存储在ItemLoader中。待所有数据收集完成，ItemLoader.load_item()方法将被调用，构建并返回Item对象。此时，伴随着前面提取的数据输出处理器将被调用。输出处理器的结果将是Item的最终值。 下面通过一个例子来阐明输入、输出处理器针对特定字段是怎样被调用的(其他字段是同样的原理)：123456l = ItemLoader(Product(),some_selector)l.add_xpath('name',xpath1) # 1l.add_xpath('name',xpath2) # 2l.add_css('name',css) # 3l.add_value('name','test') # 4return l.load_item() # 5 数据从xpath1被提取，然后传递给name字段的输入处理器，输入处理器的结果被收集并保持在Item Loader中（并没有赋值给item)。 同上，数据提取后appended到1提取到的数据中。 同上，提取方法改变而已，数据提取后appended到1、2提取到的数据中。 同上，只是这里的value被转换为一个可迭代的元素，因为输入处理器只能接受可迭代的参数。数据提取后appended到1、2、3提取到的数据中。 1/2/3/4步中提取的数据被传递给输出处理器，输出处理器的结果将被赋值给item。 值得注意的是，处理器只是可调用的对象，这些对象伴随着要解析的数据被调用，并返回一个已解析的值。因此，您可以使用任何函数作为输入或输出处理器。唯一的要求是它们必须接受一个(并且只有一个)可迭代的参数。 注意：输入、输出处理器必须接受一个迭代器作为它的第一个参数。那些输出方法可任意，输入处理器的结果将被添加至一个内部的list(在Loader中)，包含收集到的该字段的值 。输出处理器的值最终将被赋给item。 最后，Scrapy自带了一些通用的处理器。 声明Item LoadersItem Loaders像Items一样使用类定义语法来声明。123456789from scrapy.loader import ItemLoaderfrom scrapy.loader.processors import TakeFirst,MapCompose,Joinclass ProductLoader(ItemLoader): defaule_output_processor = TakeFirst() name_in = MapCompose(unicode.title) name_out = Join() price_in = MapCompose(unicode.strip) # ... 如你所见，输入处理器使用_in后缀来声明，而输出处理器使用_out后缀。你也可以通过ItemLoader.default_input_processor和ItemLoader.default_output_processor定义默认的输入/输出处理器。 定义输入输出处理器官网 Feed exports New in version 0.10. 实现爬虫最常用的一个特性，用于存储爬取到的数据，通常会使用爬取到的数据生成一个“export file”（通常叫作“export feed”）。 Scrapy通过Feed Exports提供了开箱即用的功能，允许你将scraped items生成多种序列化的feed格式，并在后端存储。 序列化格式feed exports使用Item exporters序列化爬取到的数据。这些格式开箱即用: - JSON - JSON lines - CSV - XML 但是，你也可以扩展支持的格式，通过FEED_EXPORTERS设置。 JSON FEED_FORMAT:json Exporter used:JsonItemExporter JSON with large feeds.warning JSON lines FEED_FORMAT:jsonlines Exporter used:JsonLinesItemExporter CSV FEED_FORMAT:csv Exporter used:CsvItemExporter 通过FEED_EXPORT_FIELDS指定导出的列和顺序。其他格式也可以使用这个选项，但是CSV不像其他格式，它使用的是固定的头部。 XML FEED_FORMAT:xml Exporter used:XmlItemExporter Pickle FEED_FORMAT:pickle Exporter used:PickleItemExporter Marshal FEED_FORMAT:marshal Exporter used:MarshalItemExporter Storages使用URI定义存储feed的位置(通过FEED_URI设置)。feed exports支持多种后端存储格式，通过URI方案定义。后端开箱即用的存储格式： 本地文件系统 FTP S3(需要botocore 或 boto) 标准输出 如果依赖的额外库不可用的话，有的后端存储将不可用。例如：S3后端只有当botocore和boto库都已安装才可用。(Scrapy只在Python 2上支持boto) Storage URI参数存储URI还包含在创建是被替换的参数，被替换的参数如下： %(time)s 当feed被创建时用时间戳替换 %(name)s%被爬虫名称替换 其他的参数将会被爬虫的同名属性替换，如%(site_id)s在feed被创建的时候将会被spider.site_id属性替换。 下面有一些例子来解释： 使用FTP存储，每个爬虫一个目录 ftp://user:password@ftp.example.com/scraping/feeds/%(name)s/%(time)s.json 使用S3存储，每个爬虫一个目录 s3://mybucket/scraping/feeds/%(name)s/%(time)s.json Storage backends本地文件系统feeds存储在本地系统： URI scheme:文件 URI例子：file:///tmp/export.csv 额外的库：none注意：使用本地文件系统的时候，如果指定了绝对路径(/tmp/export.csv)，可以忽略scheme，但是仅在Unix系统上有效。 FTPfeeds存储在FTP服务器上 URI shceme:ftp Example URL:ftp://user:pass@ftp.example.com/path/to/export.csv 额外的库：none S3feeds存储在Amazon S3上。 URI scheme:s3 Example URIs: s3://mybucket/path/to/export.csv s3://aws_key:aws_secret@mybucket/path/to/export.csv 需要额外的库：botocore或boto AWS证书可以在URI中以user/password传输，或者可以通过以下设置传输： AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY 标准输出feeds被写进Scrapy进程的标准输出流中。 URI scheme:stdout Example URI:stdout: 需要额外的库：none 设置feed导出配置项： FEED_URI(强制的) FEED_FORMAT FEED_STORAGES FEED_EXPORTERS FEED_STORE_EMPTY FEED_EXPORT_ENCODING FEED_EXPORT_FIELDS FEED_EXPORT_INDENT FEED_URI默认：None导出feed的URI，关于URI schemes的资料查看Storage backends这个设置对于导出feed是必须的。 FEED_FORMAT序列化feed用的格式，查看[Serialization formats] FEED_EXPORT_ENCODINGDefault:None被用于feed的编码 如果没有设置或设置为None，将使用UTF-8作为除了JSON格式输出的编码，JSON使用安全数字编码(\uXXXX序列)是有历史原因的。如果你愿意，使用utf-8作为JSON编码格式也是可以的。 FEED_EXPORT_FILEDSDefault:None 被导出字段列表选项，例如:FEED_EXPORT_FIELDS=[&quot;foo&quot;,&quot;bar&quot;,&quot;baz&quot;] 使用FEED_EXPORT_FIELDS选项来定义导出的字段和顺序。 当FEED_EXPORT_FIELDS是空的或None时，Scrapy使用在dicts中定义的字段或Item子类。 如果导出需要一个固定字段的集合(如：CSV)，但FEED_EXPORT_FIELDS是空或None时，Scrapy将通过导出数据推导字段名，目前使用第一个item的字段名。 FEED_EXPORT_INDENTDefault:0输出文件不同层级的缩进空格数量。如果FEED_EXPORT_INDENT是一个非负整数，然后数组元素和对象成员将按照设定的缩进进行展示。缩进级别为0或负数，将会输出每个item到新的行。当前仅仅JsonItemExporter和XmlItenExporter可用。例如当你导出.json或.xml格式时。 FEED_STORE_EMPTYDefault:False是否允许导出空的feeds(如：没有items的feeds) FEED_STORAGESDefault:{} 项目提供的的额外feed存储后端支持。键为URI schemes，值为存储类的路径。 FEED_STORAGES_BASEDefault:1234567&#123; '':'scrapy.extensions.feedexport.FileFeedStorage', 'file': 'scrapy.extensions.feedexport.FileFeedStorage', 'stdout': 'scrapy.extensions.feedexport.StdoutFeedStorage', 's3': 'scrapy.extensions.feedexport.S3FeedStorage', 'ftp': 'scrapy.extensions.feedexport.FTPFeedStorage',&#125; Scrapy内置的一个包含feed后端存储的字典。你可以在FEED_STORAGES中配置值为None来禁用一个选项。例如：禁用内置的FTP后端存储，不是替换，把下面的代码放入settings.py中：123FEED_STORAGES=&#123; 'ftp':None&#125; FEED_EXPORTERSDefault:{}项目提供的额外exporters字典。键为序列化的格式，值为Item exporter类的路径。 FEED_EXPORTERS_BASEDefault:123456789&#123; 'json': 'scrapy.exporters.JsonItemExporter', 'jsonlines': 'scrapy.exporters.JsonLinesItemExporter', 'jl': 'scrapy.exporters.JsonLinesItemExporter', 'csv': 'scrapy.exporters.CsvItemExporter', 'xml': 'scrapy.exporters.XmlItemExporter', 'marshal': 'scrapy.exporters.MarshalItemExporter', 'pickle': 'scrapy.exporters.PickleItemExporter',&#125; Scrapy提供的内置feed exporters字典。你可以在FEED_EXPORTERS中禁止某些exporters。例如：禁止内置的CSV exporter(而不是替换)，把下面的代码放入settings.py:123FEED_EXPORTERS=&#123; &apos;csv&apos;:None,&#125; Item Exporters经常需要把爬取到的数据导出，以便其他应用使用，毕竟这是爬虫的目的。 Scrapy提供了一些不同导出格式(XML,CSV or JSON)的Item Exporters。 使用Item Exporters如果你很忙，只是想用Item Exporter导出爬取到的数据，那么请看Feed export]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pycharm]]></title>
    <url>%2F2017%2F11%2F16%2F%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%2FPython%2Fpycharm%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819Alt+Enter 自动添加包 shift+O 自动建议代码补全 Ctrl+t SVN更新 Ctrl+k SVN提交Ctrl + / 注释(取消注释)选择的行Ctrl+Shift+F 高级查找Ctrl+Enter 补全Shift + Enter 开始新行TAB Shift+TAB 缩进/取消缩进所选择的行Ctrl + Alt + I 自动缩进行Ctrl + Y 删除当前插入符所在的行Ctrl + D 复制当前行、或者选择的块Ctrl + Shift + J 合并行Ctrl + Shift + V 从最近的缓存区里粘贴Ctrl + Delete 删除到字符结尾Ctrl + Backspace 删除到字符的开始Ctrl + NumPad+/- 展开或者收缩代码块Ctrl + Shift + NumPad+ 展开所有的代码块Ctrl + Shift + NumPad- 收缩所有的代码块 在PyCharm /opt/pycharm-3.4.1/help目录下可以找到ReferenceCard.pdf快捷键英文版说明 PyCharm Default KeymapPyCharm3.0默认快捷键(翻译的)12345678910111213141516171819202122232425262728293031323334353637381、编辑（Editing）Ctrl + Space 基本的代码完成（类、方法、属性）Ctrl + Alt + Space 快速导入任意类Ctrl + Shift + Enter 语句完成Ctrl + P 参数信息（在方法中调用参数）Ctrl + Q 快速查看文档Shift + F1 外部文档Ctrl + 鼠标 简介Ctrl + F1 显示错误描述或警告信息Alt + Insert 自动生成代码Ctrl + O 重新方法Ctrl + Alt + T 选中Ctrl + / 行注释Ctrl + Shift + / 块注释Ctrl + W 选中增加的代码块Ctrl + Shift + W 回到之前状态Ctrl + Shift + ]/[ 选定代码块结束、开始Alt + Enter 快速修正Ctrl + Alt + L 代码格式化Ctrl + Alt + O 优化导入Ctrl + Alt + I 自动缩进Tab / Shift + Tab 缩进、不缩进当前行Ctrl+X/Shift+Delete 剪切当前行或选定的代码块到剪贴板Ctrl+C/Ctrl+Insert 复制当前行或选定的代码块到剪贴板Ctrl+V/Shift+Insert 从剪贴板粘贴Ctrl + Shift + V 从最近的缓冲区粘贴Ctrl + D 复制选定的区域或行Ctrl + Y 删除选定的行Ctrl + Shift + J 添加智能线Ctrl + Enter 智能线切割Shift + Enter 另起一行Ctrl + Shift + U 在选定的区域或代码块间切换Ctrl + Delete 删除到字符结束Ctrl + Backspace 删除到字符开始Ctrl + Numpad+/- 展开折叠代码块Ctrl + Numpad+ 全部展开Ctrl + Numpad- 全部折叠Ctrl + F4 关闭运行的选项卡 2、查找/替换(Search/Replace)12345F3 下一个Shift + F3 前一个Ctrl + R 替换Ctrl + Shift + F 全局查找Ctrl + Shift + R 全局替换 3、运行(Running)123456Alt + Shift + F10 运行模式配置Alt + Shift + F9 调试模式配置Shift + F10 运行Shift + F9 调试Ctrl + Shift + F10 运行编辑器配置Ctrl + Alt + R 运行manage.py任务 4、调试(Debugging)123456789F8 跳过F7 进入Shift + F8 退出Alt + F9 运行游标Alt + F8 验证表达式Ctrl + Alt + F8 快速验证表达式F9 恢复程序Ctrl + F8 断点开关Ctrl + Shift + F8 查看断点 5、导航(Navigation)1234567891011121314151617181920212223242526272829Ctrl + N 跳转到类Ctrl + Shift + N 跳转到符号Alt + Right/Left 跳转到下一个、前一个编辑的选项卡F12 回到先前的工具窗口Esc 从工具窗口回到编辑窗口Shift + Esc 隐藏运行的、最近运行的窗口Ctrl + Shift + F4 关闭主动运行的选项卡Ctrl + G 查看当前行号、字符号Ctrl + E 当前文件弹出Ctrl+Alt+Left/Right 后退、前进Ctrl+Shift+Backspace 导航到最近编辑区域Alt + F1 查找当前文件或标识Ctrl+B / Ctrl+Click 跳转到声明Ctrl + Alt + B 跳转到实现Ctrl + Shift + I查看快速定义Ctrl + Shift + B跳转到类型声明Ctrl + U跳转到父方法、父类Alt + Up/Down跳转到上一个、下一个方法Ctrl + ]/[跳转到代码块结束、开始Ctrl + F12弹出文件结构Ctrl + H类型层次结构Ctrl + Shift + H方法层次结构Ctrl + Alt + H调用层次结构F2 / Shift + F2下一条、前一条高亮的错误F4 / Ctrl + Enter编辑资源、查看资源Alt + Home显示导航条F11书签开关Ctrl + Shift + F11书签助记开关Ctrl + #[0-9]跳转到标识的书签Shift + F11显示书签 6、搜索相关(Usage Search)123Alt + F7/Ctrl + F7文件中查询用法Ctrl + Shift + F7文件中用法高亮显示Ctrl + Alt + F7显示用法 7、重构(Refactoring)12345678910F5复制F6剪切Alt + Delete安全删除Shift + F6重命名Ctrl + F6更改签名Ctrl + Alt + N内联Ctrl + Alt + M提取方法Ctrl + Alt + V提取属性Ctrl + Alt + F提取字段Ctrl + Alt + C提取常量Ctrl + Alt + P提取参数 8、控制VCS/Local History1234Ctrl + K提交项目Ctrl + T更新项目Alt + Shift + C查看最近的变化Alt + BackQuote(’)VCS快速弹出 9、模版(Live Templates)12Ctrl + Alt + J当前行使用模版Ctrl +Ｊ插入模版 10、基本(General)123456789Alt + #[0-9]打开相应的工具窗口Ctrl + Alt + Y同步Ctrl + Shift + F12最大化编辑开关Alt + Shift + F添加到最喜欢Alt + Shift + I根据配置检查当前文件Ctrl + BackQuote(’)快速切换当前计划Ctrl + Alt + S 打开设置页Ctrl + Shift + A查找编辑器里所有的动作Ctrl + Tab在窗口间进行切换 一些常用设置： pycharm默认是自动保存的，习惯自己按ctrl + s 的可以进行如下设置： file -&gt; Setting -&gt; General -&gt; Synchronization -&gt; Save files on frame deactivation 和 Save files automatically if application is idle for .. sec 的勾去掉 file -&gt;Setting -&gt; Editor -&gt; Editor Tabs -&gt; Mark modified tabs with asterisk 打上勾 Alt + Enter: 自动添加包 对于常用的快捷键，可以设置为visual studio(eclipse…)一样的：file -&gt; Setting -&gt; Keymap -&gt; Keymaps -&gt; vuisual studio -&gt; Apply Pycharm中默认是不能用Ctrl+滚轮改变字体大小的，可以在file -&gt; Setting -&gt;Editor-〉Mouse中设置 要设置Pycharm的字体，要先在file -&gt; Setting -&gt;Editor-〉Editor中选择一种风格并保存，然后才可以改变 在setting中搜索theme可以改变主题，所有配色统一改变]]></content>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webpack]]></title>
    <url>%2F2017%2F11%2F04%2F%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%2Fwebpack%2F</url>
    <content type="text"><![CDATA[入口(Entry)入口起点告诉webpack从哪里开始1234//webpack.config.jsmodule.exports = &#123; entry:'./path/to/my/entry/file.js'&#125; 出口(Output)将所有资源assets归拢在一起后，还需要告诉 webpack 在哪里打包应用程序。webpack 的 output 属性描述了如何处理归拢在一起的代码(bundled code)。12345678910//webpack.config.jsconst path = require('path');module.exports = &#123; entry: './path/to/my/entry/file.js', output: &#123; path: path.resolve(__dirname, 'dist'), filename: 'my-first-webpack.bundle.js' &#125;&#125;; 在上面的例子中，我们通过 output.filename 和 output.path 属性，来告诉 webpack bundle 的名称，以及我们想要生成(emit)到哪里。 loaderwebpack 的目标是，让 webpack 聚焦于项目中的所有资源(asset)，而浏览器不需要关注考虑这些（明确的说，这并不意味着所有资源(asset)都必须打包在一起）。webpack 把每个文件(.css, .html, .scss, .jpg, etc.) 都作为模块处理。然而 webpack 自身只理解 JavaScript。 webpack loader 在文件被添加到依赖图中时，其转换为模块。 在更高层面，在 webpack 的配置中 loader 有两个目标。 识别出(identify)应该被对应的 loader 进行转换(transform)的那些文件。(test 属性)转换这些文件，从而使其能够被添加到依赖图中（并且最终添加到 bundle 中）(use 属性)1234567891011121314151617//webpack.config.jsconst path = require('path');const config = &#123; entry: './path/to/my/entry/file.js', output: &#123; path: path.resolve(__dirname, 'dist'), filename: 'my-first-webpack.bundle.js' &#125;, module: &#123; rules: [ &#123; test: /\.txt$/, use: 'raw-loader' &#125; ] &#125;&#125;;module.exports = config; 以上配置中，对一个单独的 module 对象定义了 rules 属性，里面包含两个必须属性：test 和 use。这告诉 webpack 编译器(compiler) 如下信息： “嘿，webpack 编译器，当你碰到在 require()/import 语句中被解析为 ‘.txt’ 的路径时，在你对它打包之前，先使用 raw-loader 转换一下。” 重要的是要记得，在 webpack 配置中定义 loader 时，要定义在 module.rules 中，而不是 rules。然而，在定义错误时 webpack 会给出严重的警告。 插件(plugins)然而由于 loader 仅在每个文件的基础上执行转换，而 插件(plugins) 更常用于（但不限于）在打包模块的 “compilation” 和 “chunk” 生命周期执行操作和自定义功能（查看更多）。webpack 的插件系统极其强大和可定制化。 想要使用一个插件，你只需要 require() 它，然后把它添加到 plugins 数组中。多数插件可以通过选项(option)自定义。你也可以在一个配置文件中因为不同目的而多次使用同一个插件，这时需要通过使用 new 来创建它的一个实例。1234567891011121314151617181920212223//webpack.config.jsconst HtmlWebpackPlugin = require('html-webpack-plugin'); //installed via npmconst webpack = require('webpack'); //to access built-in pluginsconst path = require('path');const config = &#123; entry: './path/to/my/entry/file.js', output: &#123; path: path.resolve(__dirname, 'dist'), filename: 'my-first-webpack.bundle.js' &#125;, module: &#123; rules: [ &#123; test: /\.txt$/, use: 'raw-loader' &#125; ] &#125;, plugins: [ new webpack.optimize.UglifyJsPlugin(), new HtmlWebpackPlugin(&#123;template: './src/index.html'&#125;) ]&#125;;module.exports = config; 更多详细内容查看官网 插件123html-webpack-plugin: index.html自动插入jsclean-webpack-plugin: 清理文件夹WebpackManifestPlugin: 文件映射提取到json 开发开发工具：inline-source-map （不能用于生产环境）webpack-dev-server（开启开发服务器，如果现在修改和保存任意源文件，web服务器就会自动重新加载编译后的代码。)webpack-dev-middleware]]></content>
      <categories>
        <category>前端开发</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebSocket(python端)]]></title>
    <url>%2F2017%2F10%2F24%2F%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%2FWebSocket%E6%9C%8D%E5%8A%A1%E7%AB%AF%EF%BC%88Python%EF%BC%89%2F</url>
    <content type="text"><![CDATA[UDP通讯12345678910import socketport=8081s=socket.socket(socket.AF_INET,socket.SOCK_DGRAM)#从指定的端口，从任何发送者，接收UDP数据s.bind((&apos;&apos;,port))print(&apos;正在等待接入...&apos;)while True: #接收一个数据 data,addr=s.recvfrom(1024) print(&apos;Received:&apos;,data,&apos;from&apos;,addr) TCP通讯1234567891011121314151617181920212223242526272829303132333435363738394041424344#-*- coding: utf-8 -*-from socket import *from time import ctimefrom time import localtimeimport timeHOST=&apos;&apos;PORT=1122 #设置侦听端口BUFSIZ=1024ADDR=(HOST, PORT)sock=socket(AF_INET, SOCK_STREAM)sock.bind(ADDR)sock.listen(5)#设置退出条件STOP_CHAT=Falsewhile not STOP_CHAT: print(&apos;等待接入，侦听端口:%d&apos; % (PORT)) tcpClientSock, addr=sock.accept() print(&apos;接受连接，客户端地址：&apos;,addr) while True: try: data=tcpClientSock.recv(BUFSIZ) except: #print(e) tcpClientSock.close() break if not data: break #python3使用bytes，所以要进行编码 #s=&apos;%s发送给我的信息是:[%s] %s&apos; %(addr[0],ctime(), data.decode(&apos;utf8&apos;)) #对日期进行一下格式化 ISOTIMEFORMAT=&apos;%Y-%m-%d %X&apos; stime=time.strftime(ISOTIMEFORMAT, localtime()) s=&apos;%s发送给我的信息是:%s&apos; %(addr[0],data.decode(&apos;utf8&apos;)) tcpClientSock.send(s.encode(&apos;utf8&apos;)) print([stime], &apos;:&apos;, data.decode(&apos;utf8&apos;)) #如果输入quit(忽略大小写),则程序退出 STOP_CHAT=(data.decode(&apos;utf8&apos;).upper()==&quot;QUIT&quot;) if STOP_CHAT: breaktcpClientSock.close()sock.close()]]></content>
      <tags>
        <tag>网络通信</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebSocket]]></title>
    <url>%2F2017%2F10%2F24%2F%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%2FWebSocket%2F</url>
    <content type="text"><![CDATA[WebSocket协议的使用方法 引用自阮一峰的博客 http协议通信只能由客户端发起 websocket没有产生之前，客户端要实时获取服务器状态，只能采用轮询的方式。应用场景：聊天室 websocket诞生于2008年，2011年成为国际标准 特点：服务器可以向客户端推送消息，客户端也可以向服务器推送，实现双向通信。属于服务器推送技术的一种。 http和websocket的对比特点：1.建立在 TCP 协议之上，服务器端的实现比较容易。2.与 HTTP 协议有着良好的兼容性。默认端口也是80和443，并且握手阶段采用 HTTP协议，因此握手时不容易屏蔽，能通过各种 HTTP 代理服务器。3.数据格式比较轻量，性能开销小，通信高效。4.可以发送文本，也可以发送二进制数据。5.没有同源限制，客户端可以与任意服务器通信。6.协议标识符是ws（如果加密，则为wss），服务器网址就是 URL。 客户端实现123456789101112131415var ws = new WebSocket(&quot;wss://echo.websocket.org&quot;);ws.onopen = function(evt) &#123; console.log(&quot;Connection open ...&quot;); ws.send(&quot;Hello WebSockets!&quot;);&#125;;ws.onmessage = function(evt) &#123; console.log( &quot;Received Message: &quot; + evt.data); ws.close();&#125;;ws.onclose = function(evt) &#123; console.log(&quot;Connection closed.&quot;);&#125;; 客户端API1、WebSocket构造函数1var ws =new WebSocket(&apos;ws://localhost:8080&apos;); ws所有的方法和属性参见这里 2、WebSocket.readyState共有四种： CONNECTING：值为0，表示正在连接。 OPEN：值为1，表示连接成功，可以通信了。 CLOSING：值为2，表示连接正在关闭。 CLOSED：值为3，表示连接已经关闭，或者打开连接失败。 1234567891011121314151617switch (ws.readyState) &#123; case WebSocket.CONNECTING: // do something break; case WebSocket.OPEN: // do something break; case WebSocket.CLOSING: // do something break; case WebSocket.CLOSED: // do something break; default: // this never happens break;&#125; 3、WebSocket监听事件 ws.onopen() 指定连接成功后的回调函数 123ws.onopen = function()&#123; ws.send(&apos;Hello Server!&apos;)&#125; ws.onclose() 指定关闭连接后的回调函数 12345ws.onclose = function(evt)&#123; var code = event.code; var reason = event.reason; var wasClean = event.wasClean;&#125; ws.onmessage() 指定收到服务器数据后的回调函数 123456789101112ws.onmessage = function(event) &#123; var data = event.data; // 处理数据,有可能收到的是二进制数据 if(typeof data === String) &#123; console.log(&quot;Received data string&quot;); &#125; if(data instanceof ArrayBuffer)&#123; var buffer = data; console.log(&quot;Received arraybuffer&quot;); &#125;&#125;; 除了动态判断收到的数据类型，也可以使用==binaryType==属性，显式指定收到的二进制数据类型。 1234567891011// 收到的是 blob 数据ws.binaryType = &quot;blob&quot;;ws.onmessage = function(e) &#123; console.log(e.data.size);&#125;;// 收到的是 ArrayBuffer 数据ws.binaryType = &quot;arraybuffer&quot;;ws.onmessage = function(e) &#123; console.log(e.data.byteLength);&#125;; ws.onerror() 实例对象的onerror属性，用于指定报错时的回调函数。 123socket.onerror = function(event) &#123; // handle error event&#125;; 4、WebSocket的方法 ws.send() 实例对象的send()方法用于向服务器发送数据 1234567891011121314151617181920(1)发送文本 ws.send(&apos;your message&apos;);(2)发送Blob对象(发送文件) var file = document .querySelector(&apos;input[type=&quot;file&quot;]&apos;) .files[0]; ws.send(file); (3)发送ArrayBuffer对象(发送图片等二进制) // Sending canvas ImageData as ArrayBuffer var img = canvas_context.getImageData(0, 0, 400, 320); var binary = new Uint8Array(img.data.length); for (var i = 0; i &lt; img.data.length; i++) &#123; binary[i] = img.data[i]; &#125; ws.send(binary.buffer); 5、WebSocket.bufferedAmount实例对象的bufferedAmount属性，表示还有多少字节的二进制数据没有发送出去。它可以用来判断发送是否结束。12345678var data = new ArrayBuffer(10000000);socket.send(data);if (socket.bufferedAmount === 0) &#123; // 发送完毕&#125; else &#123; // 发送还没结束&#125; 服务端实现查看wiki文档 常见Node实现的三种方案： µWebSockets Socket.IO WebSocket-Node Python实现socket握手 12345678910111213141516配置：config = &#123; &apos;HOST&apos;:&apos;127.0.0.1&apos;, &apos;PORT&apos;:8888, &apos;LISTEN_CLIENT&apos;:10, &apos;KEY&apos;:&apos;391f10fadc339e9ec5fa15af60030ac1&apos;, &apos;SIZE&apos;:1024, &apos;GUID&apos;:&apos;258EAFA5-E914-47DA-95CA-C5AB0DC85B11&apos;, &apos;TIME_OUT&apos;:1000, &apos;HANDSHAKE_STRING&apos;:&quot;HTTP/1.1 101 Switching Protocols\r\n&quot; \ &quot;Upgrade:websocket\r\n&quot; \ &quot;Connection: Upgrade\r\n&quot; \ &quot;Sec-WebSocket-Accept: &#123;1&#125;\r\n&quot; \ &quot;WebSocket-Location: ws://&#123;2&#125;/chat\r\n&quot; \ &quot;WebSocket-Protocol:chat\r\n\r\n&quot;&#125; 1、服务端创建和销毁socket 12345678910111213import socket//TCP ws = socket.socket(AF_INET,SOCK_STREAM)//UDP ws = socket.socket(AF_INET,SOCK_DGRAM)//关闭socket ws.close() 或者 ws.shutdown(arg) 0:阻止socket 接收数据 1:阻止发送 2:阻止接收和发送 2、绑定IP：端口1234//监听本地8080端口发过来的数据ws.bind(&apos;127.0.0.1&apos;,8080)//监听任何IP地址的8080端口ws.bind(&apos;&apos;,8080) 3、监听12//监听数量,这个数值表示在等待队列中允许放置的进来的连接总数。当等待队列已满时，如果有更多的连接到达，那么远程端将被告知连接被拒绝ws.listen(5) 4、接收数据1234循环监听white True: # 接收数据，返回socket q(data) 和 地址v(ip:port) client,address = ws.accept() Python实现客户端1234import socketclient = socket.socket(AF_INET,SOCK_STREAM)client.connect((&apos;127.0.0.1&apos;,8080)) 通信：1234567ws.send(&apos;hello,I am Server!&apos;)//recv(bufsize[,flags]),flags: MSG_OOB:处理带外数据（既TCP紧急数据）。 MSG_DONTROUTE:不使用路由表；直接发送到接口。 MSG_PEEK:返回等待的数据且不把它们从队列中删除。q.recv(1024) WebSocketdWebSocket服务器：WebSocketd 后台脚本不限语言，标准输入（stdin）就是 WebSocket 的输入，标准输出（stdout）就是 WebSocket 的输出。]]></content>
      <tags>
        <tag>网络通信</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django框架]]></title>
    <url>%2F2017%2F10%2F18%2F%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%2FPython%2FDjango%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[Python的web框架有Django、Tornado、Flask等多种Django的优势：ORM、模型绑定、模版引擎、缓存、Session 框架知识点： 流程 基本配置 路由系统 视图view 模版 Model模型 中间件 Form 认证系统 CSRF 分页 Cookie Session 缓存 序列化 信号 admin 事务（Transaction） 装饰器 模块 Q 装饰器 函数装饰器 类装饰器 函数装饰器 装饰器本身也是一个函数，它的作用是在不改动其他函数代码的前提下为其增加额外的功能，装饰器的返回值也是一个函数。 带参数的装饰器 不带参数的装饰器 不带参数的装饰器12def foo(): print &apos;i am foo&apos; 需求：要记录foo的执行日志123def foo(): print &apos;i am foo&apos; log.info(&apos;foo is running&apos;) 一个函数有这个需求还好办，如果有10个函数都需要记录日志，这样写不仅费事，而且很不优雅。改进：12345def add_logging(func): func() log.info(&apos;foo is running&apos;)add_logging(foo) 这样是可以，但是改变了原来的逻辑，原先执行foo()变成了执行add_logging(foo)为了让代码更优雅，装饰器诞生了。12345678910111213简单的装饰器:def add_logging(func): def _func(*args,**kws): log.info(func.__name__ + &apos; is running&apos;) return func return _funcdef foo(): print &apos;i am foo&apos;foo = add_logging(foo)foo() 每次都要进行foo = add_logging(foo)的赋值操作，会显得麻烦。装饰器的语法糖@符号，在定义函数的时候使用，避免再次赋值12345@add_loggingdef foo(): print &apos;i am foo&apos;foo() 带参数的装饰器在上面的例子中，装饰器的唯一参数就是执行业务的函数。装饰器语法允许我们在调用时，提供其他参数。这样就为装饰器的编写提供了更大的灵活性。123456789101112def add_logging(level): def _func(func): def __func(*args,**kws): log.info(func.__name__ + &apos; is running&apos;) return func return __func return _func@add_logging(level=&apos;1&apos;)def foo(): print &apos;i am foo&apos; 模块 inspect inspect 对是否是模块，框架，函数等进行类型检查。 获取源码 ==获取类或函数的参数的信息== 解析堆栈 数据库事务Database transactions数据库事务(Database Transaction) ，是指作为单个逻辑工作单元执行的一系列操作，要么完全地执行，要么完全地不执行。 事务处理可以确保除非事务性单元内的所有操作都成功完成，否则不会永久更新面向数据的资源。通过将一组相关操作组合为一个要么全部成功要么全部失败的单元，可以简化错误恢复并使应用程序更加可靠。一个逻辑工作单元要成为事务，必须满足所谓的ACID（原子性、一致性、隔离性和持久性）属性。事务是数据库运行中的逻辑工作单位，由DBMS中的事务管理子系统负责事务的处理。 举例：设想网上购物的一次交易，其付款过程至少包括以下几步数据库操作：一、更新客户所购商品的库存信息二、保存客户付款信息–可能包括与银行系统的交互三、生成订单并且保存到数据库中四、更新用户相关信息，例如购物数量等等正常的情况下，这些操作将顺利进行，最终交易成功，与交易相关的所有数据库信息也成功地更新。但是，如果在这一系列过程中任何一个环节出了差错，例如在更新商品库存信息时发生异常、该顾客银行帐户存款不足等，都将导致交易失败。一旦交易失败，数据库中所有信息都必须保持交易前的状态不变，比如最后一步更新用户信息时失败而导致交易失败，那么必须保证这笔失败的交易不影响数据库的状态–库存信息没有被更新、用户也没有付款，订单也没有生成。否则，数据库的信息将会一片混乱而不可预测。数据库事务正是用来保证这种情况下交易的平稳性和可预测性的技术。 使用：1234from django.db import transactionwith transaction.atomic(): pass django定时任务(unix环境)传送门1pip install django-crontab settings.py配置：INSTALLED_APPS添加1&apos;django_crontab&apos; 同样在settings文件中添加：1234567CRONJOBS=[ (&apos;*/10 * * * *&apos;,&apos;app.cron.checkOrderToCancel&apos;,[],&#123;&#125;,&apos;&apos;)] ``` app应用中新建文件cron.py: def checkOrderToCancel(): pass```]]></content>
      <categories>
        <category>后端开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[swig语法]]></title>
    <url>%2F2017%2F10%2F17%2F%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%2FSwig%2F</url>
    <content type="text"><![CDATA[一、起航1、API1234567891011swig.init(&#123; allowErrors: false, autoescape: true, cache: true, encoding: &apos;utf8&apos;, filters: &#123;&#125;, root: &apos;/&apos;, tags: &#123;&#125;, extensions: &#123;&#125;, tzOffset: 0&#125;) options: allowErrors: 默认值为 false。将所有模板解析和编译错误直接输出到模板。如果为 true，则将引发错误，抛出到 Node.js 进程中，可能会使您的应用程序崩溃。 autoescape: 默认true，强烈建议保持。字符转换表请参阅转义过滤器。 true: HTML安全转义 false: 不转义，除非使用转义过滤器或者转义标签 ‘js’: js安全转义 cache: 更改为 false 将重新编译每个请求的模板的文件。正式环境建议保持true。 encoding: 模板文件编码 root: 需要搜索模板的目录。如果模板传递给 swig.compileFile 绝对路径(以/开头)，Swig不会在模板root中搜索。如果传递一个数组，使用第一个匹配成功的数组项。 tzOffset: 设置默认时区偏移量。此设置会使转换日期过滤器会自动的修正相应时区偏移量。 filters:自定义过滤器或者重写默认过滤器，参见自定义过滤器指南。tags: 自定义标签或者重写默认标签，参见自定义标签指南。extensions: 添加第三方库，可以在编译模板时使用，参见参见自定义标签指南。 2、node.js123456var tpl = swig.compileFile(&quot;path/to/template/file.html&quot;);var renderedHtml = tpl.render(&#123; vars: &apos;to be inserted in template&apos; &#125;);或者var tpl = swig.compile(&quot;Template string here&quot;);var renderedHtml = tpl(&#123; vars: &apos;to be inserted in template&apos; &#125;); 3、结合Express1234567npm install expressnpm install consolidate然后app.engine(&apos;.html&apos;,cons.swig);app.set(&apos;view engine&apos;,html); 4、浏览器Swig浏览器版本的api基本与nodejs版相同，不同点如下： 不能使用swig.compileFile，浏览器没有文件系统 你必须提前使用swig.compile编译好模板 按顺序使用extends, import, and include，同时在swig.compile里使用参数templateKey来查找模板 12var template = swig.compile(&apos;&lt;p&gt;&#123;% block content %&#125;&#123;% endblock %&#125;&lt;/p&gt;&apos;, &#123; filename: &apos;main&apos; &#125;);var mypage = swig.compile(&apos;&#123;% extends &quot;main&quot; %&#125;&#123;% block content %&#125;Oh hey there!&#123;% endblock %&#125;&apos;, &#123; filename: &apos;mypage&apos; &#125;); 二、基础1、变量1&#123;&#123;foo.bar&#125;&#125;或&#123;&#123;foo[&apos;bar&apos;]&#125;&#125; 如果变量未定义，输出空字符串变量可以通过过滤器来修改：12&#123;&#123; name|title &#125;&#125; was born on &#123;&#123; birthday|date(&apos;F jS, Y&apos;) &#125;&#125;// Jane was born on July 6th, 1985 2、逻辑标签3、注释4、空白模板里的空白在最终输出时默认保留，如果需要去掉空白，可以在逻辑标签前后加上空白控制符’—‘：123&#123;% for item in seq -%&#125; &#123;&#123;item&#125;&#125;&#123;%- endfor%&#125; 三、模板继承Swig使用extends和block来实现模板继承1234567891011121314151617181920212223242526&lt;!--layout.html--&gt;&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;&#123;% block title %&#125;My Site&#123;% endblock %&#125;&lt;/title&gt; &#123;% block head%&#125; &lt;link rel=&quot;stylesheet&quot; href=&quot;main.css&quot;&gt; &#123;% endblock %&#125;&lt;/head&gt;&lt;body&gt; &#123;% block content%&#125;&#123;%endblock%&#125;&lt;/body&gt;&lt;/html&gt;&lt;!--index.html--&gt;&#123;%extends &apos;layout.html&apos;%&#125;&#123;%block title%&#125;My Page&#123;%endblock%&#125;&#123;%block head%&#125; &#123;%parent%&#125; &lt;link rel=&quot;stylesheet&quot; href=&quot;custom.css&quot;&gt;&#123;%endblock%&#125;&#123;%block content%&#125; &lt;p&gt;This is just a simple page.&lt;/p&gt;&#123;%endblock%&#125; 四、变量过滤器用于修改变量。变量名称后用“|”字符分隔添加过滤器。也可以添加多个过滤器。 1、例子12&#123;&#123; name|title &#125;&#125; was born on &#123;&#123;birthday|date(&apos;F jS,Y&apos;)&#125;&#125;and has &#123;&#123; bikes|length|default(&quot;zero&quot;)&#125;&#125; bikes. 也可以使用==filter标签==来为块内容添加过滤器1&#123;% filter upper %&#125;oh hi,swig!&#123;% endfilter %&#125; 2、内置过滤器 add(value):使变量与value相加，数值字符串会自动转换为数值 addslashes:用\转义字符串 caplitalize:大写首字母 data(format[,tzOffset]):转换日期为指定格式 format:格式 tzOffset:时区 default(value):默认值 escape([type]):转义字符 默认: &amp;,&lt;,&gt;,”,’ js：&amp;,&lt;,&gt;,”,’,=,-,; first: 返回数组第一个值 join(glue):同[].join json_encode([indent]):类似JSON.stringfy,indent为缩进空格数 last:返回数组最后一个值 length:返回变量的length,如果是object，返回key的数量 lower:同’’.toLowerCase() raw:指定输入不会被转义 replace(search,replace[,flags]):同’’.replace reverse:翻转数组 striptags:去除html/xml标签 title:大写首字母 uniq:数组去重 upper:同’’.toUpperCase url_encode:同encodeURIComponent url_decode:同decodeURIComponent 3、自定义过滤器创建一个myfilter.js然后引入到Swig的初始化函数中1swig.init(&#123;filters:require(&apos;myfilter&apos;)&#125;); 在myfilter.js里，每一个filter方法都是一个简单的js方法，下例是一个翻转字符串的filter:1234567exports.myfilter = function(input)&#123; return input.toString().split(&apos;&apos;).reverse().join(&apos;&apos;);&#125;exports.prefix = function(input,prefix)&#123; return prefix.toString() + input.toString();&#125; 使用：12345&#123;&#123; name|myfilter &#125;&#125;或者&#123;% filter myfilter %&#125; I shall be filtered&#123;% endfilter %&#125; 过滤器传参：1234567&lt;!--字符串--&gt;&#123;&#123; name|prefix(&apos;hello &apos;) &#125;&#125;或者&#123;%filter prefix &apos;hello &apos;%&#125; yang &#123;% endfilter %&#125;&lt;!--变量--&gt;&#123;% filter prefix foo %&#125;I will be prefixed with the value stored to `foo`.&#123;% endfilter %&#125; 4、标签 extends: 使当前模板继承父模板，必须在文件最前面 参数file:父模板相对模板root的相对路径 block:定义一个块，使之可以被继承的模板重写，或者重写父模板的同名块 参数name:定义一个块，使之可以被继承的模板重写，或者重写父模板的同名块 parent:将父模块中同名块注入当前块中 include:包含一个模板到当前位置，这个模板将使用当前上下文 参数file:包含模板相对模板root的相对路径 参数ignore missing:包含模板不存在也不会报错 参数with x:设置x至根上下文对象以传递给模板生成。必须是一个键值对 参数only:限制模板上下文中用with x定义的参数 本地申明的上下文变量，默认情况下不会传递给包含的模板。 12345&#123;% set foo = &quot;bar&quot; %&#125;&#123;% include &quot;inc.html&quot; %&#125;&#123;% for bar in thing %&#125; &#123;% include &quot;inc.html&quot; %&#125;&#123;% endfor %&#125; 错误:inc.html无法得到foo和bar 如果想把本地申明的变量引入到包含的模板中，可以使用with参数来把后面的对象创建到包含模板的上下文中 12345&#123;% set foo = &#123; bar: &quot;baz&quot; &#125; %&#125;&#123;% include &quot;inc.html&quot; with foo %&#125;&#123;% for bar in thing %&#125; &#123;% include &quot;inc.html&quot; with bar %&#125;&#123;% endfor %&#125; 如果当前上下文中foo和bar可用，下面的情况，只有foo会被inc.html定义 1&#123;% include &quot;inc.html&quot; with foo only %&#125; only 必须作为最后一个参数，放在其他位置会被忽略。 raw：停止解析标记中的任何内容，所有内容将原样输出 file:父模板相对模板 root 的相对路径 for:遍历对象和数组 x:当前循环迭代名 in:语法标记 y:可迭代对象。可以使用过滤器修改 12345&#123;% for x in y %&#125; &#123;% if loop.first %&#125;&lt;ul&gt;&#123;% endif %&#125; &lt;li&gt;&#123;&#123; loop.index &#125;&#125; - &#123;&#123; loop.key &#125;&#125;: &#123;&#123; x &#125;&#125;&lt;/li&gt; &#123;% if loop.last %&#125;&lt;/ul&gt;&#123;% endif %&#125; &#123;% endfor %&#125; loop.index：当前循环的索引（1开始） loop.index0：当前循环的索引（0开始） loop.revindex：当前循环从结尾开始的索引（1开始） loop.revindex0：当前循环从结尾开始的索引（0开始） loop.key：如果迭代是对象，是当前循环的键，否则同 loop.index loop.first：如果是第一个值返回 true loop.last：如果是最后一个值返回 true loop.cycle：一个帮助函数，以指定的参数作为周期 1234loop.cycle() 循环设置奇偶行的样式&#123;% for item in items %&#125; &lt;li class=&quot;&#123;&#123; loop.cycle(&apos;odd&apos;, &apos;even&apos;) &#125;&#125;&quot;&gt;&#123;&#123; item &#125;&#125;&lt;/li&gt;&#123;% endfor %&#125; 在for标签里使用else，当people为undefined或null时执行else 12345&#123;% for person in people %&#125; &#123;&#123; person &#125;&#125;&#123;% else %&#125; There are no people yet!&#123;% endfor %&#125; if：条件语句 参数:接受任何有效的javasript条件语句 123456789101112131415161718192021&#123;% if x %&#125;&#123;% endif %&#125;&#123;% if !x %&#125;&#123;% endif %&#125;&#123;% if not x %&#125;&#123;% endif %&#125;&#123;% if x and y %&#125;&#123;% endif %&#125;&#123;% if x &amp;&amp; y %&#125;&#123;% endif %&#125;&#123;% if x &amp;&amp; y %&#125;&#123;% endif %&#125;&#123;% if x or y %&#125;&#123;% endif %&#125;&#123;% if x || y %&#125;&#123;% endif %&#125;&#123;% if x || (y &amp;&amp; z) %&#125;&#123;% endif %&#125;&#123;% if x [operator] y %&#125; Operators: ==, !=, &lt;, &lt;= , &gt;, &gt;=, ===, !==&#123;% endif %&#125;&#123;% if x == &apos;five&apos; %&#125; The operands can be also be string or number literals&#123;% endif %&#125;&#123;% if x|length === 3 %&#125; You can use filters on any operand in the statement.&#123;% endif %&#125;&#123;% if x in y %&#125; If x is a value that is present in y, this will return true.&#123;% endif %&#125; else和else if 12345678&#123;% if foo %&#125; Some content.&#123;% else if &quot;foo&quot; in bar %&#125; Content if the array `bar` has &quot;foo&quot; in it.&#123;% else %&#125; Fallback content.&#123;% endif %&#125; autoescape：改变当前变量的自动转义行为 on：当前内容是否转义Boolean type：转义类型，js或者html，默认html 假设1some_html_output = &apos;&lt;p&gt;Hello &quot;you&quot; &amp; \&apos;them\&apos;&lt;/p&gt;&apos;; 然后123456789&#123;% autoescape false %&#125; &#123;&#123; some_html_output &#125;&#125;&#123;% endautoescape %&#125;&#123;% autoescape true %&#125; &#123;&#123; some_html_output &#125;&#125;&#123;% endautoescape %&#125;&#123;% autoescape true &quot;js&quot; %&#125; &#123;&#123; some_html_output &#125;&#125;&#123;% endautoescape %&#125; 输出123&lt;p&gt;Hello &quot;you&quot; &amp; &apos;them&apos;&lt;/p&gt; &amp;lt;p&amp;gt;Hello &amp;quot;you&amp;quot; &amp;amp; &amp;#39;them&amp;#39; &amp;lt;/p&amp;gt; \u003Cp\u003EHello \u0022you\u0022 &amp; \u0027them\u0027\u003C\u005Cp\u003E set：设置一个变量,在当前上下文中复用 name:变量名 =语法标记 value:变量值 123&#123;% set foo = [0, 1, 2, 3, 4, 5] %&#125; &#123;% for num in foo %&#125; &lt;li&gt;&#123;&#123; num &#125;&#125;&lt;/li&gt;&#123;% endfor %&#125; macro:创建自定义可复用的代码段 参数…:用户自定义 1234&#123;% macro input type name id label value error %&#125; &lt;label for=&quot;&#123;&#123; name &#125;&#125;&quot;&gt;&#123;&#123; label &#125;&#125;&lt;/label&gt; &lt;input type=&quot;&#123;&#123; type &#125;&#125;&quot; name=&quot;&#123;&#123; name &#125;&#125;&quot; id=&quot;&#123;&#123; id &#125;&#125;&quot; value=&quot;&#123;&#123; value &#125;&#125;&quot;&#123;% if error %&#125; class=&quot;error&quot;&#123;% endif %&#125;&gt;&#123;% endmacro %&#125; 使用:123456&lt;div&gt; &#123;&#123; input(&quot;text&quot;, &quot;fname&quot;, &quot;fname&quot;, &quot;First Name&quot;, fname.value, fname.errors) &#125;&#125;&lt;/div&gt;&lt;div&gt; &#123;&#123; input(&quot;text&quot;, &quot;lname&quot;, &quot;lname&quot;, &quot;Last Name&quot;, lname.value, lname.errors) &#125;&#125;&lt;/div&gt; 输出:12345678&lt;div&gt; &lt;label for=&quot;fname&quot;&gt;First Name&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;fname&quot; id=&quot;fname&quot; value=&quot;Paul&quot;&gt;&lt;/div&gt;&lt;div&gt; &lt;label for=&quot;lname&quot;&gt;Last Name&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;lname&quot; id=&quot;lname&quot; value=&quot;&quot; class=&quot;error&quot;&gt;&lt;/div&gt; import：允许引入另一个模板的宏进入当前上下文 file:引入模板相对模板root的相对路径 as:语法标记 var:分配给宏的可访问上下文对象 12345&#123;% import &apos;formmacros.html&apos; as form %&#125; &#123;# this will run the input macro #&#125;&#123;&#123; form.input(&quot;text&quot;, &quot;name&quot;) &#125;&#125;&#123;# this, however, will NOT output anything because the macro is scoped to the &quot;form&quot; object: #&#125;&#123;&#123; input(&quot;text&quot;, &quot;name&quot;) &#125;&#125; filter:对整个块应用过滤器 filter_name:过滤器名字 …:若干传给过滤器的参数 使用 123456&#123;% filter uppercase %&#125; oh hi, &#123;&#123; name &#125;&#125;&#123;% endfilter %&#125;&#123;% filter replace &quot;.&quot; &quot;!&quot; &quot;g&quot; %&#125; Hi. My name is Paul.&#123;% endfilter %&#125; 输出 OH HI, PAUL Hi! My name is Paul! spaceless:尝试移出html标签间的空格 使用 12345&#123;% spaceless %&#125;&#123;% for num in foo %&#125; &lt;li&gt;&#123;&#123; loop.index &#125;&#125;&lt;/li&gt;&#123;% endfor %&#125;&#123;% endspaceless %&#125; 输出 &lt;li&gt;1&lt;/li&gt;&lt;li&gt;2&lt;/li&gt;&lt;li&gt;3&lt;/li&gt;]]></content>
      <tags>
        <tag>模版</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中国佛教发展简史略述——南怀瑾]]></title>
    <url>%2F2016%2F09%2F01%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F%E4%B8%AD%E5%9B%BD%E4%BD%9B%E6%95%99%E5%8F%91%E5%B1%95%E7%AE%80%E5%8F%B2%E7%95%A5%E8%BF%B0%E2%80%94%E2%80%94%E5%8D%97%E6%80%80%E7%91%BE%2F</url>
    <content type="text"><![CDATA[南怀瑾：1918-2012年，从军、经商、游历、考察、讲学。毕生致力于民族振兴和改善社会人心，于中华传统文化之儒、道、佛皆有造诣。 法不孤起 人世间难以料者是事，善于变化者是人。 &#160; 本书思路： 佛教哲学思想的由来 教主释迦牟尼的生平 佛教的传播 空间地区的传播 时间线的发展 四大文明古国：中国、印度、埃及、希腊。古希腊文化成就现在的欧美文化，希腊文化代表西方。印度文化后历汉季而宋世，已经全盘融汇于中国文化。 世界文明：宗教——&gt;哲学——&gt;科学 &#160; 佛教前期文化的孕育： &#160; 佛教起源于印度，于两汉时期传入中国。印度位于南亚半岛，地理气候有南北东西及中央地区的明显差别。南印度接近热带，北印靠近喜马拉雅山气候稍冷，中印度为温带气候，古代印度一年只分三季，每季四个月。接近热带，人们的身心动态、思想多于行动，尤其接近南印度地带的，更富于神奇的幻想。当时学派林立，思想学说，各成一方。人文生活，有一特点，就是阶级区分，非常严格，贵贱异等，苦乐悬殊。 印度人的四种姓氏制度：婆罗门：世袭而职司祭祀的专业僧侣，位居上等，宗教文化教育的中心，凡军国政治，也都为其左右。刹帝利：王侯武士，集军政权于一族，为世袭的统治者。吠舍：拥有财货的商贾阶级。首陀罗：从事耕种的农民阶级。 婆罗门掌管文化教育，依据《四吠陀典》崇尚“神人”“神我”的思想，形成印度历史文化中心的“婆罗门教”，渐次影响到印度人三种姓的思想意识：婆罗门、刹帝利、吠舍。始终倾向于出世的沙门（修道人）生活。他们理想的人生历程，分为四个时期： 净行时期：少年时代的教育生活，到达一定年龄（婆罗门：8-16岁，刹帝利：11-20岁，吠舍：12-24岁）出家就学，学习吠陀等学问，经过规定年限期（如：12年、24年、36年或48年等）满学业成就，便可回家还俗。 家居时期：壮年时期的生活，可以结婚生子，负责家庭生活，善尽一家之主的责任。 林栖时期：中年时期栖隐山林、潜心修道，学习各种禅定思维的方法，以求“神我”的升华。 遁世时期：进入衰老的岁月，修行生活告一段落，身心绝对净化，道果业已圆成，从此便遁迹山林，再不参与世事。随着新思潮的鼓荡，刹帝利逐渐不满婆罗门的思想统治，所以才有印度文化中“奥义书”的出现，与婆罗门的传统精神互相抗衡。古代印度人的思想渊源和文化背景：地理环境和天然气候的特殊性，喜欢醉心思维。2. 早已有了根深蒂固的婆罗门教和普及的宗教思想。3. 倾向于出世思想，以求净化身心，并以林栖遁世为人生最大的享受。4. 思想高原偏向虚幻，脱离现实，中间缺乏人本主义的思想体系，致使阶级划分严格，贵贱等位悬殊，宗教的信仰都不能得到平等自由。因此，释迦牟尼应运而兴，他以慈悲宏愿，创立佛教，截长补短，存优去劣，应化众生的美善精神，梳理百代的文化传统，破除人家的阶级观念，指示人性的升华成就。 印度上古文化的宗教哲学： 1、四吠陀典（赞颂）：灵魂不灭，死后回到夜摩天。 《梨俱吠陀》赞颂，以赞颂一切自然力量的功德为主。原人，造化一切的主神。 《夜柔吠陀》祭祀，为一部献祭的祷词，分作黑、白二本，内文半为颂诗半为散文。 《娑摩吠陀》歌咏，系一部歌咏集，为婆罗门僧祭酒时所歌唱。 《阿闼婆吠陀》多属神咒，乃控制神鬼之法。 2、 净行书：原人论加以蜕变，崇奉一个造物主宰的神，梵。加上宗教哲学的因果报应，生死轮回，上天堂，下地狱。3、奥义书：印度宗教哲学，与知识分子和平民普遍的哲学总汇，上下普及，无论男女老幼，都追求心灵的解脱，灵魂的追究，世界生成等问题。 &#160; ①确定梵我不二：形而上的造物主和形而下的自我本是同一个整体，世界万象本根同源。 潜在内部的自我分为五藏与四位： 四位：①醒位②梦位③熟眠位④死位 五藏：①食味所成我 ②生气所成我 ③意识所成我 ④认识所成我 ⑤欢喜所成我 ② 大梵化生万象：地、水、火、风、空五大种子，化生卵、胎、热、湿、马、人、象等动植物。 ③轮回与解脱：天、地、空三界中轮回三道四生。三道：天道、祖道——人道、兽类和地狱道。四生：胎、卵、湿、化四类生命。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[WEB前端开发书籍]]></title>
    <url>%2F2016%2F03%2F08%2F%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%2FWEB%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%E4%B9%A6%E7%B1%8D%2F</url>
    <content type="text"><![CDATA[技能集： HTML、XHTML、HTML5、CSS、SASS、SCSS、LESS Backbone、Angular、Knockout 响应式设计(例如Bootstrap知识、Foundation等) Adobe Photoshop、Magento 源控制和某种形式的客户单元测试的知识：git push和git pull 工具集： Visual Studio Code、Sublime Webstorm Dreamweaver Eclipse Netbeans Notepad++ VIM EMACS 第一阶段：HTML和CSS的学习 1.《CSS权威指南》第三版 2.《CSS那些事儿》 3.《精通CSS：高级Web标准解决方案》第二版 4.《CSS禅意花园》--&gt;前端开发的圣经，必看 第二阶段：JavaScript的学习 1.《JavaScriptDOM编程艺术》 2.《JavaScript权威指南》第6版--&gt;JavaScript程序员的圣经,必看 3.《JavaScript高级程序设计》第三版 4.《高性能JavaScript》 5.《JavaScript王者归来》 6.《JavaScript模式》 7.《JavaScript设计模式》 第三阶段：jQUery的学习 1.《锋利的jQuery》第二版 第四阶段：学无止境 1.《瞬间之美：Web界面设计如何让用户心动》 2.《精通CSS：高级Web标准解决方案（第2版）》 3.《高性能网站建设进阶指南：Web开发者性能优化最佳实践》 4.《构建高性能Web站点》 5.《深入浅出Web设计》 6.《编写高质量代码——Web前端开发修炼之道》 7.《高性能网站建设指南》 8.《Web开发敏捷之道》第二版]]></content>
      <categories>
        <category>前端开发</category>
      </categories>
      <tags>
        <tag>书籍</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[香格里拉]]></title>
    <url>%2F2016%2F01%2F04%2F%E6%B8%B8%E8%AE%B0%2F%E9%A6%99%E6%A0%BC%E9%87%8C%E6%8B%89%2F</url>
    <content type="text"><![CDATA[2015年是藏历金羊年，羊对于高原上的藏民来说具有特殊意义，在藏民看来羊全身都是宝，羊毛制作的羊皮袄可以御寒，羊肉则是餐桌上的美食。渐渐的羊逐渐成为藏族群心目中的圣物，然而关于羊的信仰也演化成了宗教活动，在西藏流行一种说法：“马年转山，羊年转湖”，围转草原上的“纳木错”等圣湖是信徒们的重要宗教活动，据说羊年转湖的功德是普通年份的几百倍。我属羊，并且一直向往着去一次西藏，也渴望像傅真说的那样在这个神圣的地方遇到一阵穿堂风。本来跟韩哥约好国庆长假去的，但是临时计划有变，陪唐荣斌去了河南。眼瞅着2015年就快过去，我年休假也还没休，刚好2015年还剩5天，一个冲动请了年假，订了机票，跨上唐荣斌的单反只身来了香格里拉，5天时间去西藏时间不够，先来香格里拉试试水。昆明长水机场——迪庆香格里拉机场，早上8:05分的飞机，9:05分准时到，一下飞机，阵阵寒意袭来，不禁打了个哆嗦。这地方海拔高，空气稀薄，但放眼望去，感觉整个世界清晰了不少，出了机场，拼车去市里，开车的师傅是当地藏民，一脸淳朴的用云南方言跟我说价格30元，冲着这一脸的淳朴我没敢还价。半小时后来到独克宗古城门口，老师傅友善的提醒我出门在外，注意安全。时间9点40左右，古城和我想象中的差距太大了，这个点几乎没有商户开门，2014年1月的那场大火把独克宗烧的没了模样，冷清的像某个边陲山野小村庄。我独自一人走在古城的街道上，看着一间间正在翻新改造的房屋，一阵阵的油漆味扑面而来，心想：“完了，这波亏了！” 古城的尽头是月亮广场，旁边是龟山公园，站在龟山公园可以俯瞰整个独克宗。 下午去了松赞林寺，回来的时候5点左右，在古城吃的晚饭，看着这家店比较文艺，推开门就钻进去了，点了一杯酥油茶，一碗咖喱牛肉盖饭，生平第一次喝酥油茶，有点喝不惯，总觉得有股柴油的问道，但是喝下去身体又暖暖的。 晚上又去了龟山公园，夜景比白天好看多了。 早上在这里拍照的时候，一群人冲我喊，吓我一跳，走过去只听到：“就差你了。”我看了看，大概明白了，拉起一根绳子，跟着转了三圈。据说这个转经筒里藏有上万经条，转一圈功德是普通转经筒的上万倍，三圈下来我许了一个心愿：希望我妈妈身体健康。这个过程中有一个小细节，在藏民习俗中，参观还是转经都必须按顺时针方向走，不能走反了。 下来的时候遇到一只小狗，一路跟着我，看了看它，觉得它跟我好像，都那么孤单，然后给它拍了张照片，它很配合的坐下来看着镜头。 吃过午饭，去了松赞林寺，传说中的小布达拉宫，冬季的香格里拉能去的景点也不多。 松赞林寺门口干枯的拉姆央措湖 在寺内导游一路讲解，进门的台阶是143级，好巧的数字，取的是“一寺三”的谐音，一座寺庙有佛、法、僧三宝。导游在爬阶梯前问我们有没有信心爬上去，我心里想：“143级阶梯而已，你开玩笑？”，忘了这里是高原，一口气爬到顶，回过头来准备拍湖的时候居然感觉到头有点晕，阿西吧。能够看到的三座殿供奉的分别是（左起）宗克巴、扎仓殿、释迦摩尼，参观的顺序也是从左至右，然后有八大康参分别掌管着八个地区，其他的建筑是僧侣的宿舍。在参观之前，导游给我们做了简单的讲解，佛家八宝：宝瓶、宝盖、双鱼、莲花、右旋螺、吉祥结、尊胜幢、法轮。并教了一句观世音菩萨的六字箴言：唵(ong)、嘛(ma)、呢(ni)、叭(bei)、咪(mei)、吽(hong)，让我们在殿里祈祷的时候念。 在寺内遇到一位一身白衣的上海大叔，让我帮他拍照，然后就约着一起转拉姆央措湖。大叔四十出头的样子，着装长相谈吐很像我的高中班主任，大叔给我讲了许多关于佛教的知识，什么南传佛教、北传佛教、藏传佛教、大乘、小乘等等。 转到湖中央浮桥处，看到松赞林寺倒映在水中的样子甚是壮观，拍了一张。 转回到门口，大叔坚持要给我拍一张纪念照。在这里遇到一个小姑娘，也是让我给她拍照，结果她的单反我不会弄，拍出来的照片曝光很严重，她一脸哀怨的看着我，我连忙解释道：我挎着的这个单反早上我还在看说明书。后来在她的指导下拍了几张，还算满意，她微笑着跟我道谢，很特别的一个小姑娘，笑起来跟朵花似的，后来在回独克宗的公交上又遇到了。 大叔说他想去看天葬台，我下午没什么安排，就跟着他从松赞林寺走路出来，到达天葬台路牌的时候我们才知道，天葬台居然还在那边的山顶上，想想也只能作罢。大叔来香格里拉一段时间了，明天准备去丽江，他跟我提了一点建议，冬季的普达措国家公园和纳帕海跟拉姆央措湖一个样，春夏季节会漂亮些，他刚从梅里回来，在那里看到了日照金山，还特意跟我分享了照片。回到古城，找了一家客栈住下，然后把之前做的计划一条条划掉，最后决定明天去德钦，梅里雪山和雨崩也许还值得一去。 从香格里拉——德钦，4个小时的车程，途径白马雪山，滇藏线的最高点垭口，海拔4292米。 下午2点左右到的飞来寺，和独克宗古城一样冷清，没办法淡季嘛，我是来看风景的又不是来看人的。在去哪儿网订了大叔推荐的小愉客栈，观景房198，拉开窗帘就能看到梅里。午饭在时光梅里吃的，店主都回家了，一个北京的小伙看店，看着他一身衣服不知穿了几个月，但是我看了周围的饭店好像只有这里可以吃炒饭，店里还有2个顾客，后来的遭遇让我们成了旅途的小伙伴。门口一块白布上写着一号食堂，这个北京伙子号称是这里唯一的一个一级厨师，说话奇奇怪怪的，我就吃个炒饭，搞的都快没心情了。最后和店里的另外2位顾客商量一起点菜，一人20，这2位顾客一男一女，在校学生，一开始我以为他们是一对，后面聊天才发现，也是路上认识的旅伴。这个一级厨师，磨磨唧唧的搞了半天，炒了3个菜，有一个是胡的，饭没能煮熟，然后我们就凑合着吃了。我看出了他们两的惊讶，什么一级厨师，我说：吃吧，吃不饱咋们待会儿再去别的地方买点吃的，乱七八糟的3个菜吃了60。旁边还有一位女生，他们三是住这家青旅的客人，几句话后大家便结伴出去观景，天气不太好，梅里被乌云盖住了，我们四个在飞来寺晃悠着，仿佛整个飞来寺冷清的只有我们4个游客。晚饭一起去另外一家餐厅吃的火锅，总算可以大快朵颐了，一个下午下来大家便熟了起来，他们邀我去青旅聊天，我一个人住小愉客栈也是孤单，就跟着过去。之前没有上去看他们的住宿条件，20元一个床位，味道很难闻，2位女生想洗一下脸，去找水，没有。然后下去问北京小伙，小伙带着耳机不搭理，再叫他只是反复重复一句话，二楼有个白色的桶，你们拿着桶去打水，我们找了好几圈都没找到。下去再问，还是同样的话，丽娜姐憋不住了，跟北京小伙吵了起来，张慈娟和朱兆凯是学生，站在旁边不敢说话。我早就觉得这个人不正常，说话奇奇怪怪的，我也过去帮她，我说：他们住你的店，就是你的顾客，花费不了你几分钟，你就站起来帮他们找一下就怎么了？他反问我：你住这里吗？我说：没有，我们是朋友。他说他女朋友被人撬走了，现在没精神。我去你大爷，你是个神经病吧？看着娜姐憋红了的脸，我也不知道说什么好。后来北京小伙冒出一句：你们要住不住，不住退房。然后他们3果真退了房，跟我去住小愉客栈了，这个客栈全是双标，我订的也是双标，小朱跟我一间，他是学生，没收他费用，娜姐和小张一间。接下来的几天总算不是那么孤单了，我们一起约着去等梅里现身，一起吃饭，一起聊天，总算有小伙伴了。。。 为什么我总是拍小狗？ 小愉客栈 一直等到第四天，天气终于放晴了 梅里雪山上的冰川，站在飞来寺拍的。 雪山脚下的小村落：西当 第三天，他们都走了，去了丽江。没看到梅里，我的假期也还没完，其他地方也不太想去，于是我留下来了。换了一家住宿，搬到了守望6740青旅，35一个床位，环境也还将就。和老板聊天，大理人，大理我熟啊，5月份在洱源呆了一个月，聊着聊着简直成了半个老乡。老板娘是藏民，他们有一个小女儿，我去屋顶拍照的时候，跟在我后面扑哧扑哧的。 屋顶有个吊椅，专门用来赏雪山的 守望6740，6740是梅里雪山主峰卡瓦格博的海拔，云南最高峰。 第二天早上7点就起来了，天气好转，万里无云。 天渐渐的亮了起来 第一缕阳光洒在卡瓦格博身上 渐渐的又金山的感觉 直到阳光洒满了梅里十三峰，临走的时候他们嘱咐我一定要拍到日照金山，到时候给他们发过去。 等了4天，可能是诚意打动了卡瓦格博老爷爷，总算让我看到了梅里雪山的全貌，《转经》中说有的人去过无数次梅里，都无缘见到卡瓦格博的全貌，看来我还算幸运的。来的时候kindle里买了一本书：《消失的地平线》，走的时候刚好看完。]]></content>
      <categories>
        <category>游记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[梅里雪山外转经]]></title>
    <url>%2F2015%2F12%2F27%2F%E6%B8%B8%E8%AE%B0%2F%E6%A2%85%E9%87%8C%E9%9B%AA%E5%B1%B1%E5%A4%96%E8%BD%AC%E7%BB%8F%2F</url>
    <content type="text"><![CDATA[转自：http://tieba.baidu.com/p/3538922351 梅里雪山位于横断山脉，云南和西藏的交界。是三江并流世界自然遗产的核心地区。主峰卡瓦格博是云南第一高峰，藏区八大神山之首。为藏传佛教宁玛派分支伽居巴的保护神。1991年一场震惊世界的山难让全世界都知道了这里。每年秋末无数的藏民都会以他们独有的方式来这里朝拜，这就是我们所称的转山。 这是一条七百多年的朝圣路，是莲花生大师在禅定中预言的胜乐金刚佛二十四胜地之一，是元代佛学大师噶玛巴西活佛发现并指点给世人的无与伦比的圣地。藏传佛教徒相信,每转一次山，都可以消除一些罪孽，使灵魂得到净化；每一次转经完成都意味着自己向梦想中的天国更近了一步；在朝圣途中陨灭意味着灵魂得到超生，进入了天堂。转经路是一条只有虔诚、勇敢的人才能完成的道路，一条沟通梦想中天堂的道路，一次终身难忘的探险之旅。 藏族人认为转山苦行一圈能消除今生的一些罪孽，给来世积下一些功德，很多人几乎每年都去转山。藏族人转山的装具也较简易，用背夹背上单薄的被褥，再带一些糌粑面、酥油、茶叶等简单食物，杵上一根转山竹便上路了。也有旅游者去转山猎奇，但终归是游客，带了一大堆户外装备和十多天的食物，背不了，只好雇骡马驮，一出发，便是山间铃响马帮来. 为什么要转经？江措（男，60岁，西藏自治区察遇县擦瓦龙乡阿丙村人。一生中外转经走了28圈，每年转一圈。）说：“人们在劳动和生活中会杀死很多生命会造成很多罪过，所以人们选择转卡瓦格博神山，也就是说通过非常辛苦的方式来惩罚自己，从而能减少罪过增加积德。转经路上要向卡瓦格博神山祈祷，保佑自己和其它转山人的平安，以及家里所有生命平安。祈祷神山洗清自己的罪过，在今后的生活中吉祥如意。路上要帮助别人，说话不要伤人。若你没有慈悲心，转经再辛苦也没有用。” 卡瓦格博海拔6740米，它从海拔6000多米的雪山穿越山腰的茫茫森林一直延伸到2000米的江边。对于登山界来说，海拔7000米以下的山峰不是被列入登山名单的，但只有卡瓦格博是例外。在一百多年的现代登山史上，14座8000米以上的山峰，几十座7000米以上的山峰都被印上登山者足迹之后，唯有这座6740米的山峰仍然保持着她的圣洁，在一次次失败的尝试之后，拒绝人类的染指。 在十几年前，这座山峰几乎不为外界所知，虽然历史上的最著名的茶马古道就经过这里远去西藏。1950年代，茶马古道衰落之后，滇藏交界处的德钦县仿佛天荒地远，从昆明出发，至少需要一个星期才能到达。1987年日本人向中国国家体委提出攀登卡瓦格博的申请的时候，云南省体委的人问北京：卡瓦格博在哪里？当地藏民按自己的方式生活着，维护着世世代代所敬仰的神灵的寓所。直到1991年一次重大山难，才打破了神山亘古的宁静。1987年8月的夏季，一支陌生的队伍开着越野车驮着大包小包来到了雪山下。村民不知道他们是谁,来干什么的。 这支登山队，由中国和日本联合组成，主体是日本京都大学登山队。日本京都大学登山队是全日本实力最强的一支队伍，有着日本多家大财团的资金做后盾。队员中三分之一以上的人都有8000米以上的登山经验，并配备了最先进的卫星云图接收仪器，队长是日本著名气象专家井上治郎教授，副队长是中国登山家宋志义，他创造过无数次中国登山记录。 当藏民们终于知道了他们要攀登的梅里雪山就是他们心中的神山卡瓦格博，他们受到的震惊是前所未有的。我们称神山叫阿尼卡瓦格博，意思是卡瓦格博爷爷。既然是爷爷，你怎么能爬到他的头上呢。我们生活中一切都是他的赐予，山上的牧场养肥了牛羊，我们喝的每一滴水都来自山上融化的雪水。对神山不敬，神灵就会离开我们，灾难就会降临。 在那么一个偏远闭塞不通公路的地方，要不是登山队进去，他们的药材、水果和蔬菜卖给谁。此外，这对国家的对外开放也有好处。日本方面也下了不少工夫，又是送越野车，又是送面包车。这又引来新的争论：在探险者眼里，无高不可攀的观念，在卡瓦格博神山下遭遇了文化尊严的挑战。在他们看来，登山只是一项运动，没想到事情怎么会那么复杂，登山队进山要交进山费，那么多队员在当地的后勤供给要消耗老乡的农副产品，雇用人工骡马也会给当地人带来现金收入。在一片争议中，几经协商，国务院批准了登山计划。1990年冬天来临的时候，经过两年多的准备，中日联合登山队在周密调查的基础上，制定了新的攀登路线。这一次，他们志在必得，一定要登顶。在神山对面的飞来寺前举行了一个盛大的出发仪式，队员们带着日本出发时当地寺庙送的护身符，又接受了喇嘛们的祝福。 1990年12月28日上午11时30分，突击队5名队接近主峰背后的山脊，到达6200米的高度，这是卡瓦格博从未有过的攀登高度，三号营地的队友得到消息，敲盆敲碗为即将到来的胜利而欢呼。然而，就在这个时候，天气突然转坏，乌云遮没了山顶，风也开始刮起来了。 日本队员船原尚武在日记中写道：天气越来越坏，风也越刮越大，卡瓦格博的脸躲在一大块很厚的云层中。我们坚持不住了，准备往下撤。到了晚上10点15分，风突然停住了，乌云散去，月光把雪地照得亮堂堂的。11点13分，突击队安全地回到三号营地。这次突击顶峰功败垂成，5名队员大难不死。这次冲顶的成果，是观察了最后的地形，结论是：已经没有克服不了的难点了。为此，登山队摆酒庆祝，6470米，对攀登卡瓦格博峰来说，已经是一个前所未有的高度了。藏民也得知登山队即将登顶的消息。村民们此时已经不再针对登山队了，而是将他们的不满对着卡瓦格博。那时老百姓不知该怎么表达他们的愤怒，他们说：阿尼卡瓦格博，显示出你的神威吧，否则，我们就不再敬你了！成千上万的喇嘛以及藏民在飞来寺诅咒登山队，信仰的力量，以及各式各样的传说让这次登山充满了宿命的意义。鉴于28日冲顶的经验，登山队决定，登顶日期定为1991年1月1日。但是，从29日开始暴雪突至，天地一片迷茫，把三号营地被死死封住。登顶日期不得不一再后延。 1月4日一大早，感到四周有一种出奇的安静，已经7点半了，居然没有听到山上的对讲机的声音。 往常，山上的队员起得很早，五六点就开始吵他们。他打开了对讲机，对方没有声音。半个小时过去，对讲机的那头异样的安静。开始还以为他们睡懒觉，但随着时间一分一秒地过去，大本营的工作人员开始紧张起来，所有人都拿着一部对讲机不停地呼叫着。三号营地17个人，都是很有经验的登山者，而且17部对讲机不可能同时出问题。9点钟很快就到了，和营地的队员失去联系这么长时间，是出发以来的四十多天里从来没有发生过的事情。 经过7天漫长的等待，中国登山队派出的救援小组终于赶到大本营，实力最强的西藏登山队在仁青平措的带领下，日夜兼程从拉萨赶来。滇藏公路两千多公里路程，平日至少需要6天时间，他们两天就赶到了。遗憾的是，救援队到达的时候实际上已经变成了搜索队。几天过去，山上的队员已经不可能存活了。两支队伍加在一起，十名顶级高手聚集一堂，但在铺天盖地的暴雪面前，冲击显得微不足道，他们选择了几条不同的上山路线，都失败了，只有西藏登山队到达一号营地，但无法接近二号营地。 二号营地是关键位置，到达二号营地，就能知道三号营地到底发生了什么。1月9日，来了一架侦察机乘云层散开的瞬间，在高空飞了几个来回，拍了照片，三号营地所在位置有30万吨以上的云团样物体堆积，判断是雪崩。京都大学的救援队也到了，可是西藏队上不去，日本队就更上不去了。1月21日指挥部正式宣布17名队员失踪，搜救行动失败。22号救援队宣布撤离。卡瓦格博难以攀登有着特殊的原因，横断山脉复杂的地质构造和低纬度雪山瞬息万变的气候，使它潜藏着致命的危险。就在宣布搜救失败、指挥部下撤的当天，大本营附近发生了一场可怕的雪崩。一片宽300米、长400米的冷杉林，树的直径都在50厘米以上，在雪崩过后，杉树林齐刷刷地倒伏在地，一棵不剩。 十几年过去，灾难发生时的恐怖情形依然如故。在那里放牧的老乡说：这是很奇怪的，这片树林并没有在发生雪崩线路上，仅仅是雪崩的气浪就把树林摧毁了。老百姓说，这是神山的又一次警告。然而，山难却使卡瓦格博越显神秘。接下来的几年里，中国登山协会接到了许多国家和地区的登山申请。对于登山者来说，雪山只是一个高度和海拔，攀登一座从未被攀登过的山峰，是很刺激的，尤其是这座山峰发生了登山史上如此著名的事件。出于对死难者的感情，云南省为京都大学登山队保留了五年的首登权。1996年首登权期限的最后一年，京都大学登山队再次进入卡瓦格博。这次登山使得争论再次升级。在当地人看来，侵犯神山就是侵犯他们的生活，这是完全不能接受的。 村民以他们的方式捍卫神山的庄严。山上每个村庄人全部下山，躺在路上的，躺在澜沧江桥上的，告诉登山队如果要攀登卡瓦格博神山先从他们身上踩过去。然而，最终使得1996年登山失败的，不是村民的阻挠，不是队员技术有问题，依然是冥冥之中支配一切的某种力量。 登顶指日可待，但一个令人心忧的消息从万里之遥的东京气象厅传了过来：未来两天内将有一个巨大的暴风雪过程，可能要超过91年的那次降雪。他们寻问了中央气象台和云南气象台，结果是吻合的。在他们的头顶，乌云正在聚集，手中的气象仪也显示暴风雪就要来了。大本营开了紧急会议，马上命令山上的队员迅速撤营，能丢的丢，能弃的弃，只要能活着回来就行。本来从四号营地到大本营，要6天的时间，他们就一天跑下来了。就在队员们刚刚到达大本营的时候，他们同时接到三地的气象预报，印度洋的暖湿气流把云层吹走了，未来仍然是晴好的天气过程，队员们想重新开始，但已经不可能了。他们在飞来寺灌木丛中的十七勇士纪念碑前长跪不起，出发时在此发下的誓死登顶的誓言，经不住山峰的一阵风雪而永远地飘走了。 1997年2月6日的《迪庆日报》写到，《读卖新闻》记者告诉中方队员：日本京都大学登山队将永远放弃梅里雪山。金飞彪是登山队的中方队员，他还记得，他们经过的每个村子，藏民们都非常反对，说触犯神灵会带来灾难，还告诉他们：91年之后，出现过一些特大的冰雹，新修小水电站变压器烧了，牲口又跌死很多，庄稼也歉收了。在山上，通过对讲机，他们得知飞来寺整天烟雾缭绕，聚集了上万人在那里烧香，祈祷神灵带来平安，也在诅咒登山的这些人，不能让他们成功。中国人有句老话：想做成一件事，需要天时、地利、人和。但是，对攀登卡瓦格博来说，却是什么都没对上号。对于1991年的山难，藏民们有他们的解释：那一年卡瓦格博到印度开神山大会，不在家，回来的时候，发现怎么有几个人爬在肩膀上，于是他一抖，就把他们抖下来了。 2003年是藏历水羊年，这一年踏上转山路的朝圣者就在十万人以上。 梅里雪山是所有信奉藏传佛教民众的朝觐圣地，自古以来，她在藏民心中是至尊、至圣、至神的象征，她的宗教地位是至高无上的，被世代藏民奉为八大神山之一。 攀登梅里雪山诸峰是对神灵的亵渎和蔑视，是不符合国家的民族宗教政策的行为，是对民族和宗教信仰的一种伤害。自此当地gov-ern-ment立法拒绝任何国家、组织和个人以任何理由登顶梅里雪山，民间对此事的说法：“在藏人眼里，梅里雪山是神圣不可侵犯的圣灵之山，只可顶礼膜拜，岂可踩于脚下。中日联合登山队要攀登梅里雪山，在藏民心里，是很难接受的。所以，在登山队向雪山攀登之时，数万藏民，包括僧侣默坐在雪山前诵经祈祷忏悔。你想，那么多人同一方向对着雪山发出声音，其声音频率相同，就引发共振，导致了雪崩。登山队全军覆没，这是大家意想不到的。这再一次证明，梅里神山是不能征服的，只可远观膜拜，不可登临踏足。”由于山势陡峭，河谷深切，路途艰险遥远，香客们风餐露宿，徒步跋涉，难免有死于中途者。但人们并不以此为不幸，反倒认为是人生最好的结局。朝山是山地民族共有的一种宗教文化和生态环境相结合的传统活动；然而藏族转经人那种不畏艰辛，舍生忘死的执著追求，却将其推向极致，是任何山地民族望尘莫及的！ 在宗教信仰者的眼中，梅里雪山是极乐世界的宫殿，是至高无上的神灵；在地质学家的眼中，梅里雪山是印度洋板块撞击欧亚板块的杰作；在生物家的眼中，梅里雪山是生物多样性的王国；而在登山探险家的眼中，梅里雪山则是他们大显身手的用武之地。不过，梅里雪山不愧为神山禁地，它屡屡挫败人类企图爬到它的头顶蹦蹦跳跳的尝试，包括卡格博、缅茨姆在内的诸多雪山，至今仍是万众瞩目，无人染指的处女峰。 “挠痒痒”酿成灭顶之灾 20世纪30年代，周游过全球许多名山大川的美国学者洛克博士，有感于梅里雪山的恢宏壮丽，赞美它是“世界上最美之山”然而，被梅里雪山的美色所征服的人类，近一个世纪来，也不断梦想着把它踩在脚下，以示征服。 1902年，英国一支探险队首次向神山梅里雪山挑战，受挫之后，大不列颠的绅士们知难而退，再也没有打它的主意。 抗日战争期间，一架美国飞机误闯神山禁地，试图飞越卡格博峰顶，结果坠入冰川，机毁人亡。40多年后，1988年6月，由遇难飞行员的儿子克里奇率领的一支美国登山队，不远万里而来，想寻回父亲的遗骸。这支登山队爬到海拔4200米的高度已筋疲力尽，无功而返。 1989年10月，中日联合登山队在斯农建立大本营，沿着西北山脊首次攀登卡格博峰，竭尽全力到达主峰北侧海拔5300米处，路遇无法逾越的大冰河和大断层。这个海拔高度比之两年前的日本山岳登山队提高了800米，但距峰顶的垂直高度仍有1440米之遥，只得甘拜下风，败下阵来。 梅里雪山海拔6740米，至今仍是一座无人登上其顶峰的“处女峰”。1991年1月4日，17名中日联合登山队队员在攀登梅里雪山过程中遇难，当地gov-ern-ment立法禁止攀登此山。谁也不曾想，在20年后的今天，又一名探险家因为攀登梅里雪山失踪，让人牵挂和揪心。高家虎，这个素来喜欢独来独往的云南登山家，由于攀登梅里雪山，已经与外界失去联系近半个月。朋友和他的最后一次联系，是收到他在海拔5400米的地方发的短信，说自己患了肺水肿…… 高家虎的一些相关信息。高家虎，又名野虎，今年36岁，是一名专业登山队员，自从1998年辞去工作开始，曾独自徒步穿越独龙江、雅鲁藏布大峡谷、青藏高原、阿尔金山、塔克拉玛干沙漠、丝绸之路、高黎贡山等地。他还在2003年12月份发现了第二批中日联合登山队队员的遗骸。 2004年8月29日，高家虎把自己捡到的遗物亲手交给遇难者家属，并同时把自己为了缅怀17勇士而谱写的歌曲从心底唱了出来，歌曲的名字叫《牵挂》。 2005年7月，高家虎出版了自己的个人传记《我定成为峰》，书中他有一句话：我！野虎。誓将成为站在梅里顶峰的第一个人！书中第59页又写道：“雪山太强大了，强大得必须抬起头仰视它。在这种仰视中，我发现，我有必要爬上他的顶峰……” 2006年1月18日晚上，高家虎在云南昆明驼峰客栈—国际青年旅馆组织了梅里雪山登山者遇难15周年山难现场回顾。同时，他还写下了一首诗，其中有一句是：“这些年来，我一直想做一件事——研究梅里雪山，探索她，发现她，朝拜她，然后皈依她”。失踪前发短信说自己患肺水肿,昨天上午10点多，曾是昆明黑风登山队队员的王辉给本报打来电话称，他知道高家虎的下落。王辉说，上个月24日傍晚，高家虎曾用一个陌生的手机号给他发过4条短信，询问他肺水肿的症状。并说自己现在在梅里雪山5400米的地方，因为上山速度太快，不能适应高度，自己有吐黄水、肺部有气泡声、身体乏力、头痛等症状，此后就再也没有联系。“真心希望他能平安归来。”王辉说，高家虎喜欢独来独往，对攀登梅里雪山一事已经达到疯狂痴迷的程度，每年他都要去登梅里雪山，而且他曾经从不同角度攀登过，并誓言要做站在顶峰的第一人，为此已经花掉了十几万元。“如果高家虎真的患了肺水肿，多半凶多吉少。”王辉分析说，“肺水肿是对登山者最大的威胁，一旦患了肺水肿，体力迅速失去80%~90%，如果不在短时间之内迅速撤离到低海拔地区，并得到及时救治，就会有生命危险。在5400米的高度，几乎不可能在短时间之内撤离，至少需要2天时间。” 梅里雪山主峰海拔6740米，珠穆朗玛峰主峰8843米，为什么人类可以多次攀登珠穆朗玛峰，但就是没有办法征服梅里雪山呢？ 梅里雪山海拔虽然只有6740米，但是要从海拔2300米的澜沧江边登上海拔6740米的高度，其消耗的体力非常大。而珠穆朗玛峰虽然有8843米高，但是车辆可以直接到达珠峰大本营，那里的海拔为5500米。人力只需要付出约3300米就可以登顶。 珠穆朗玛峰虽然高，但是坡度较小，容易攀登，而梅里雪山虽然比珠峰低，但是山坡的陡峭程度远比珠穆朗玛峰大。坡度大，也大大增加了发生雪崩的可能。梅里雪山是中国发生雪崩最频繁的雪山。之所以如此，原因在于梅里雪山被两条直通海洋的大江夹在中间，西侧是怒江，东侧是澜沧江。海洋上的潮湿空气顺着两条大江而上，一直到达梅里雪山，北部被高山阻挡，这样，潮湿的云雾就停留在这里，一遇北方来的冷空气就降起雪来，所以整个雪山的雪源丰富，冰川也十分发达。由于坡度大，冰川的流动速度是世界半海洋性冰川中最快的。 拔希当初的转经之路，现已是经典的梅里外转路线，每逢卡瓦博格的本命年——藏历羊年，因传说此年转山能功德倍增，朝圣者更是络绎不绝，常达十万以上。]]></content>
      <categories>
        <category>游记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[轿子雪山]]></title>
    <url>%2F2015%2F12%2F27%2F%E6%B8%B8%E8%AE%B0%2F%E8%BD%BF%E5%AD%90%E9%9B%AA%E5%B1%B1%2F</url>
    <content type="text"><![CDATA[轿子雪山离昆明其实不近，自驾游的话当天去当天回，不过回到家估计也是晚上十一二点；坐车的话2天，周六下午坐车到转龙休息一晚，第二天早上从转龙包车去风景区，下午回昆明。 早晨5:50起床，6点10分出门，和老程约好6:30在北部客运站碰面，结果早上的地铁都是从北部发往南部，回来的很少，等到7点10分终于来了，老程订了昆明-转龙7:50的票（票价38），班车走走停停，到转龙11点半左右。下车和2个云大研一的女生一起包车去往轿子雪山风景区，人均30元，30多公里路，大概半小时路程。 12:30到四方景游客服务中心，门票+摆渡车费用84/人，门口有许多小吃摊，在那吃了午饭，买了一双手套（15元）和鞋套（15元），山上很冷，手套很有必要，鞋套主要是保障在雪地里行走的时候鞋子不湿。然后排队乘坐摆渡车从四方景到下坪子，下坪子是一个很平坦的地方，很多人在那打雪仗。抬头就可以看到冰瀑布以及一间间堆着雪的小房子。 有没有一种隐士居住的感觉？ &nbsp; 上山有2种选择，徒步和索道，建议看看缆车排队情况再做定夺，不要急着买票。由于我们去的时候是周末，人很多，坐缆车排队都排了一个多小时，徒步早就上去了。还有那缆车有一个不得不吐槽的地方，缆车很小只够2个人坐，门比较窄，而且速度不慢，上下的时候几乎需要跑进去，稍不留神就摔倒，这使得老程和我钻进缆车都废了一番周折。缆车上可以看到山上的树木都被雪染成白色，还有山间的小溪都被冰冻了。下缆车就到了3850米的海拔，有个岔路花溪和大黑箐，去的时候大黑箐这条路被堵了，走上去一小段就得回头，不过还好有一个冰冻的小瀑布聊以慰藉。 溪水都被冰冻了 其实爬上去也不简单 看了小瀑布后无路可走，只好退回来走花溪方向，有个瀑布群，分别是飞来瀑布，莲花瀑布和天来瀑布。 飞来瀑布 有没有很壮观 本想去和冰柱合影，奈何爬不上去 古有霸王举鼎，今有老程举冰块 莲花瀑布 天来瀑布 接着往上，到了3950米海拔的精怪塘，其实这里就是一个水塘，只是被冰冻了，冰厚到人们可以在上面随意玩耍而不必担心会掉下去。 老程在京东上买的滑雪板派上用场 看到地上的轨迹没有，只是速度有点慢 从精怪塘上来左边去往一线天和天池，右边去往轿子顶，由于时间有限，我们选择登顶，放弃了一线天和天池。 登顶路上供游客休息的小房子，注意看这雪像蛋糕一样糊在房子上上面就是轿子顶，这一段稍微有点陡，轿顶上面没什么风景，海拔4223米。 从轿顶下来，在精怪塘滑雪，直到6点半游客都走完了，太阳也落山了，才不舍的小跑着下山，此时路上已经快看不到了，就在看到缆车处灯亮的前一秒我还在想我们要被困在山上了，明天早上准是2座冰雕。到缆车处刚好七点，工作人员都准备下班了，我们搭着最后一班缆车下山。 还好早上和包车的司机约好，付了一半的车费，她信守承诺来接我们。回到转龙时已经九点了，去吃了酸菜猪脚火锅，味道不错，老板娘人也很好，菜点多了吃不完，也开开心心的就给我们退了。周末人很多，建议提前预定酒店，免得大街小巷的去找都是客满，好不容易找到一家，双人标间50元，热水+wifi，环境一般，累了一天也顾不得那么多，付了房费躺下就睡了。]]></content>
      <categories>
        <category>游记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[象棋巫师]]></title>
    <url>%2F2015%2F12%2F21%2F%E6%B8%B8%E8%AE%B0%2F%E8%B1%A1%E6%A3%8B%E5%B7%AB%E5%B8%88%2F</url>
    <content type="text"><![CDATA[每天下班都要从江岸小区的盘龙江边经过，今天没骑车，走路回家。看到一群人围在一起，凑上去一看，又是一摆残棋的。由于爸爸喜欢下象棋，象棋便成了我们童年时代的一道玩具。出于对象棋的热爱，我停下了脚步，也当起了观众。摆棋的是一个大约35岁左右的男子，为了便于叙述，我暂且简称他A，棋局看起来很简单。A吆喝着：“各位老板，红棋黑棋随便你选，如果我走红棋，只需三步就能赢。”这时，旁边以为穿黑衣服，样子看起来有些猥琐的小哥B说话了：“你这棋怎么下？” A说：“下200赔300，下300赔500，下500赔800。” B掏出钱包拿了200元递给A。其实我心里也是痒痒的，我觉得那棋我看透了，有了破解的思路。正好，看看这小哥有没有和我想一块去。没想到这小哥一动棋子给人的感觉就是刚入门，仅仅知道象棋的基本规则，对于局他没有概念。B思索了半天，不服又掏出了200继续下，毫无悬念又输了。当时我就想这绝对是托，稍微会点象棋的肯定不会这样走，后面也证实了我的想法。这时旁边一位看上去40左右的大叔C过来：“我下300的。”还对刚才的B说：“小伙子下棋不能太快。” C果然不负众望，三步棋就破了，A也按照约定赔了500。换了新的棋局，C接着又说：“我下1000的”，A：“敢下1000，我赔你1500”。结果C大叔果然是有水平的人，眼看又要输，A想耍赖，我们站旁边的不服了，七嘴八舌的说敢出来摆残局就要愿赌服输，不然怎么玩。A无奈之下，赔了C1500，又换了新的棋局C还要下，这时A不乐意了说：“都是出来混饭吃的，我不和你下了。”我也觉得人家摆棋也不容易，你已经连胜2局了，适可而止，做事留点余地。我凑合着劝了几句C也觉得差不多了，便没有再下，只是站在旁边看。这是B又自告奋勇的上来：“我下1000，赢了你是不是赔我1500？”一听当时我就懵B了，我赶紧劝B，算了不要赌这么大，钱多了没地花么？被白了一眼。A：“对，你赢了我陪你1500。”没想到B像是突然换了大脑一般，居然赢了。这尼玛，我就算是瞎子也明白怎么回事了。这时事件的主角D出场，在C的怂恿下“这局简单，跟他下800的。”，A：“下800，赢了我赔1000。”D好像胜券在握的样子，爽快的把800块递到A手里，我想劝都来不及。但是看D，中年男子，戴眼镜，背着双肩包，应该是个上班族，或许人家真的看破了。可惜的是，事情往往不会像你所期望的方向发展，D输了800。A：“各位老板，有谁看出来的也可以过来下。这局最后再摆5秒钟。”C瞧瞧的跟D说了几句话（应该是告诉他怎么下），怂恿D再试一把，D说他没钱了，C说我可以借你。这时A不高兴了，对C说：“不行，你借他钱，待会你告诉他怎么下，那我这饭还怎么吃？其他所有人都可以，就是你不行。”A表现的就像为刚才C赢他钱而不高兴的样子，还让C走远一点不准说话。演的当时我都相信了，C说：“我的钱不行，其他人的总可以吧？” 然后C很热心的想帮D翻盘的样子，为了帮他把刚才输了的赢回来，主动向旁边的人借钱。这时男二号E出场，E半信半疑的借了D1000块，要了D的手机作为抵押，并且约定D赢钱了给他买一包烟，D孤注一掷，把1000全压了，我都以为他必赢的。谁知那棋局就像天龙八部里所描写的珍珑棋局一样，变幻莫测，D又输了。这时抬头看，C已经消失的无影无踪。E着急的拉着D，D要手机打电话，说是找人送钱来，就这样一路拉扯的走了二百米左右，我一直跟在后面，我突然觉得D可能也是托，出于对E的同情，我过去跟他说，你现在赶紧给你朋友打电话，让他们过来帮你，不然待会儿人家开着一卡车人来给你送钱你敢要么？（因为我想要是D也是托的话，那么带着E去取钱或者打电话叫人送钱，E的钱都不可能要回来，而且身上的其他财物还会再损失。 如果不是托，E朋友过来，情况总不会比现在糟。）E手都在抖，然后问我：“你是不是和他（D）一伙的？”我看他也是头一次遇到这种事，有些不知所措，我说：“我在那里看你们下棋看了半个多小时了，感觉你被骗了，我是想帮你。”E：“他带眼睛，你也带眼睛，而且你们还长得有点像。”我勒个擦，我直接无语了。D也推我，说：“走你的路，不要你管。”然后D和E拉拉扯扯的消失在小区的巷道中，最后我也不知道D是不是托，E的钱到底要回来没有。回来仔细想想，棋局棋局，棋是棋，局是局，很多人着迷于棋局中的局而中了局外的局。最后总结一句：每一个摆残棋的都是巫师，简称象棋巫师。 附上残局：D的思路：1. 后车平六 车４退１2. 车一平六 马６进４此时马成了变数，红棋已输。 思路1：1. 炮二进八 马６进４2. 兵五进一 将４平５3. 前车平五 将５平４4. 车五进四 将４平５5. 车一平五 将５平４6. 炮一进六 1-0 思路2：1. 炮二进八 马６进８2. 后车平六 车４退１3. 车一平六 车４退１4. 炮一进六 1-0 然而上面的都不对，网上百度了一下，这是江湖残局《马跃潭溪》的修改局，红先黑胜局。]]></content>
      <categories>
        <category>游记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[西安-秦始皇陵兵马俑]]></title>
    <url>%2F2015%2F10%2F08%2F%E6%B8%B8%E8%AE%B0%2F%E8%A5%BF%E5%AE%89-%E7%A7%A6%E5%A7%8B%E7%9A%87%E9%99%B5%E5%85%B5%E9%A9%AC%E4%BF%91%2F</url>
    <content type="text"><![CDATA[国庆节最后一站，西安。 从华山下来后，我和唐荣斌先去火车站旁的饭店取了包裹，点了一桌子的东西，吃到肚皮都鼓起来，华山上的东西实在是贵，一直没吃饱。买了晚上九点到西安的火车票，本来约了华山东峰上遇到的哥们一起的，奈何他去了老火车站。在火车站等了几个小时，终于到点了，火车开动，九点半到的西安，小钢炮已经在等着会师了。西安火车站人潮涌动，挤了半天，终于打到车，碰到彭传钢的时候他刚去大雁塔回来，据说人工喷泉很壮观，我们没赶上。把住宿安顿好，出来吃了点东西，回去躺下就睡。爬个华山把我的鞋子都爬坏了，第二天早上起来的第一件事就是出去买双新鞋子，换上舒服多了，吃了点东西，去看兵马俑。 摘自百度： 兵马俑多用模塑结合的方法制成，先用陶模作出初胎，再覆盖一层细泥进行加工刻划加彩，有的是先烧后接，有的是先接再烧，火候均匀、色泽单纯、硬度很高。 秦始皇陵位于距西安市30多公里的临潼县城以东的骊山脚下。据史书记载：秦始皇从13岁即位时就开始营建陵园，由丞相李斯主持规划设计，大将章邯监工，修筑时间长达38年，工程之浩大、气魄之宏伟，创历代封建统治者奢侈厚葬之先例。当时，秦朝总人口约2000万，而筑陵劳役达72万之多。修陵家用土，取自今陵园以南2000米的三刘村到县采石场部之间，有高5～25米的多级黄土崖。修陵园所用大量石料取自渭河北的仲山、峻峨山，全靠人力运至临潼，工程十分艰难。工程量之大可想而知,山下死尸成片,侧面显示了整个工程的残酷。它还是“世界八大奇迹”之一！ 打了一张车，女司机带着我们转啊转的，转了好几个圈，去了好几家玉石店，说是帮她攒积分，进去逛逛就行，不用买东西。今天国庆节收假，正常情况下我应该是在办公室上班了，时间紧迫，晚上还得回去赶飞机，这一晃悠浪费了不少时间。哥几个表达了一下心中的愤怒，女司机这才把我们送到兵马俑门口。 一号坑 一号坑侧面 一号坑被损坏的陶俑 据说是被楚霸王项羽一把火烧成这样，这土贼。 进行修复工作的专家 游完差不多下午4点，小钢炮要赶飞机，哥几个匆匆忙忙的去了机场。]]></content>
      <categories>
        <category>游记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[华山行]]></title>
    <url>%2F2015%2F10%2F07%2F%E6%B8%B8%E8%AE%B0%2F%E5%8D%8E%E5%B1%B1%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[毫不夸张的说，华山是我看过的最美的风景。 摘自百度： 华山古称“西岳”，中国著名的五岳之一。华山位于陕西省渭南市华阴市，在西安市以东120公里处。南接秦岭，北瞰黄渭。是道教主流全真派圣地，也是中国民间广泛崇奉的神祇，即西岳华山君神。还是神州九大观日处之一。华山观日处位于华山东峰（亦称朝阳峰），朝阳台为最佳地点。 爬完嵩山爬华山，时间不够，不然咋们恨不得把五岳都领略一把。在华山脚下的一家饭店吃了早饭，寄存了行李，原计划当天下山的，所以只带了手机钱包。旁边超市买了些吃的，饭店买了雨衣手套，就这样上山了。 西岳华山 上山有三条路线，我们选择玉泉院徒步上山，路线在上图中用红点标出。由于没有看天气预报，一整天的阴雨连绵，上山的过程中基本看不到什么风景。 华山睡仙—陈抟老祖 玉泉院门口的睡仙陈抟老祖，国庆出行，人特别多，天气也不是很好。 山脚遇到的挑山工，华山上卖的东西基本都是靠这些挑山工用肩挑上去的，所以价格也稍微贵些。 千尺幢 百尺峡 爬到百尺峡的时候已经是中午了，天气稍微放晴一点，雾气开始散开，小钢炮开始捕捉美景。 百尺峡 云梯 云梯成了这一路上稍微有点难度的关卡了，坡度近乎90度，中间一点还有超过90度的感觉，身子往后倾，手要牢牢的抓住铁索，还下着雨，前面一对情侣犹豫不决，最后放弃了。 云梯 东峰的宾馆 爬到东峰顶下午五点半左右，下半身都湿透了，小钢炮在海南呆惯了，适应不了这种境遇，于是坐索道下山去了，我和唐荣斌觉得好不容易爬上来，啥也没看到心有不甘，选择留在山上过夜，期待明天天气好转。东峰宾馆按床位计价，150元一个床位，男女混住。我两最先入住，进房间后赶紧把湿了的鞋子裤子脱了挂床边，然后缩在被子里取暖。原计划只爬一天的，所以衣服什么的全寄存在山脚，换的都没有。7点左右起来穿着依然湿透了的裤子，去旁边的东峰饭店吃了一碗炒饭48元，然后赶紧跑回来继续捂着。入住的人越来越多，居然住满了，门口窗下还躺着一堆人，租了一件大衣当被子就这样过了。抱着Kindle看《最好金龟换酒》，刚好看到傅真、毛铭基在拉丁美洲旅行的罗赖马山之旅，大便都需要用塑料袋打包带走，瞬间觉得我们这算不得什么困难。对了，今天还是我生日，农历八月二十四，新历2015年10月6日。 我定了5点半的闹铃，期待着天气好转，可以看到日出。然而凌晨5点就醒了，外面一片漆黑，还下着小雨，尽管如此还是等到了6点半，日出时间是6点10分，最后确定不可能看到日出才继续躺下睡觉。9点醒来，不断的有人道别准备下山，看了看窗外，雾很大，天空很明亮，以我从小在山里长大的经验判断，今天肯定会转晴。最后宾馆里又只剩下我和唐荣斌，我们不急着赶路，也不急着下山，躺在床上看kindle。此时，我由衷的觉得kindle是出差旅行的必备神器。11点左右，外面突然一阵叫喊声，我想肯定是出太阳了，爬到窗子边一看，果然看到一轮刺眼的太阳。我两兴奋的赶紧起床，收拾东西出发。 东峰顶 左下角可以看到瓦片的便是东峰饭店和东峰宾馆。 南峰 云海 从云层中慢慢冒出来的群峰东峰 午饭，24元/桶 有人说这是龙脉 华山西峰 传说中沉香劈山救母的地方 还真有被劈开的感觉 昨天爬山的时候裤子鞋子全湿，袜子干脆扔掉，卷起裤脚就下去了。 看上去有没有很困难的样子？ 其实只要别同时解开2条安全绳，抓紧铁链就没事了，难度系数一般。 鹞子翻身的终点，下棋亭。 长空栈道位于华山南峰东侧山腰，是华山派第一代宗师元代高道贺志真为远离尘世静修成仙，在万仞绝壁上镶嵌石钉搭木椽而筑。栈道上下皆是悬崖绝壁，铁索横悬，由条石搭成尺许路面，下由石柱固定，游人至此，面壁贴腹，屏气挪步，被誉为“华山第一天险”。 筑在光溜溜的千仞绝壁上，真正接近90度，上望崖壁好几十米，下望至少二、三百米不见谷底，栈道宽仅三十多公分，一边空悬并无栏杆，一边崖上钉有铁索可供抓手。 栈道路栈分三段，出南天门石坊至朝元洞西，路依崖凿出，长20米，宽二尺许，是为上段；折而下，崖隙横贯铁棍，形如凌空悬梯，游人须挽索逐级而下，称之“鸡下架”，是为中段；西折为下段，筑路者在峭壁上凿出石孔，楔进石桩，石桩之间架木椽三根，游人至此，面壁贴腹，脚踏木椽横向移动前行。 勇者如履长空，心旷神怡，怯者胆战心惊，屏气挪步。由于长空栈道贴崖悬空，对探险猎奇者极具诱惑性和挑战性，且栈道尽头有道教神龛贺老石室、华山十大字谜之首“全真岩”及华山卧龙松等胜景，古往今来，历险探胜者络绎不绝。 尝试了好几次之后，终于把手撑直了。 来一张合影 长空栈道的尽头，思过崖 等了一晚上，总算是有所收获，虽然没看到日出，但是看到了云海，看到了华山清晰的面貌，体验了鹞子翻身和长空栈道，感受了华山的天下第一险，于是心满意足的下山去了。]]></content>
      <categories>
        <category>游记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[洛阳-梦幻灯光节]]></title>
    <url>%2F2015%2F10%2F05%2F%E6%B8%B8%E8%AE%B0%2F%E6%B4%9B%E9%98%B3-%E6%A2%A6%E5%B9%BB%E7%81%AF%E5%85%89%E8%8A%82%2F</url>
    <content type="text"><![CDATA[洛阳—薰衣草庄园&nbsp; 计划中的洛阳站是洛阳古城和龙门石窟，但是到了洛阳之后，据当地人介绍，古城已然没有看点，只剩下古城墙；龙门石窟晚上不开放，而且里面都是一些佛像，游客大部分是中年人，不适合年轻人游玩。最后在出租车司机的强烈推荐下，载着我们来到这“薰衣草庄园”。 刚到门口的时候，看着这阵势还可以，60元/人，果断买票进去。刚进门就被这“2015梦幻灯光节”给震住了，说好的薰衣草呢？这尼玛60元的门票就看灯光？小伙伴们也纷纷表示被坑了，哄小孩呢这是。但是票都买了，没办法，那我们就顺着仰视仰视。溜了一圈赶紧撤，昨天爬了嵩山，明天还要爬华山，得好好休息。]]></content>
      <categories>
        <category>游记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[嵩山行]]></title>
    <url>%2F2015%2F10%2F05%2F%E6%B8%B8%E8%AE%B0%2F%E5%B5%A9%E5%B1%B1%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[中岳嵩山 嵩山是道教五岳圣地之一，旧时汉族民间广泛崇奉的神祇，即中岳嵩山君神。古称中岳，为中国著名的五岳之一。位于河南省西部，属伏牛山系，地处登封市西北面，是五岳的中岳。 嵩山总面积约为450平方公里，由太室山与少室山组成，最高峰连天峰1512米；东西绵延60多公里；东依省会郑州，西临古都洛阳，南依颍水，北邻黄河。地处中原，东西横卧，古称“外方”，夏商时称“嵩高”、“崇山”，西周时称天室山。公元前770年平王迁都洛阳后，以“嵩为中央、左岱、右华”，为“天地之中”，称中岳嵩山。嵩山又分为少室山和太室山两部分，共72峰。海拔最低为350米，最高处为1512米。 主峰峻极峰位于太室山，高1491.7米；最高峰连天峰位于少室山，高1512米。嵩山北瞰黄河、洛水，南临颍水、箕山，东接五代京都汴梁，西连十三朝古都洛阳，素有“汴洛两京、畿内名山”之称。于奇异的峻峰，宫观林立，故为中原地区第一名山。 徒步路线：三皇寨景区售票处——好汉坡——三皇寨——回心崖——连天吊桥——悬空栈道——塔林——少林寺(10km)时间：一天 嵩山景区示意图 从三皇寨入口仰视嵩山 奇怪的岩层 嵩山岩石&nbsp; 嵩山岩石演变完整，太古宙、元古宙、古生代、中生代、新生代的地层和岩石均有出露，被地质学界称为“五世同堂”（在地球发展历史上，历太古代、元古代、古生代、中生代、新生代五代，习称为“五世同堂”）。嵩山地区的岩浆岩、沉积岩、变质岩的出露，构成了中国最古老的岩系——“登封朵岩”。据中国地质界测定，这里是世界上稀有的自然地质宝库。嵩山古生物化石十分丰富，在嵩山既有海相生物化石，也有陆相生物化石，还有古脊椎动物化石。这些古生物化石是地质和古生物演化的宝贵数据。 据中外地质学家考察，在古老的太古宙时期，嵩山是一望无际的大海；在经历了23亿年前的“嵩阳运动”，8亿年前的“中岳运动”，5、6亿年前的“少林运动”，三次大的地壳运动之后，逐渐形成了山脉，结束了地质史上的元古代；进入了古生代的寒武纪和奥陶纪；又经过约两亿年，此处地壳上升至海平面以上，因其受风化和剥蚀作用，形成了嵩山地区的含煤地层。两亿三千年前后，在中国的版土上，又发生了一次延续很长时间的地壳运动，南北广大地区的“燕山运动”，嵩山地区受到南北方向的推挤，形成了今天的山势地貌。 天气晴朗，一件衬衫足已 人太多了，停下来休息一会 打个喷嚏也抓拍 嵩山少林寺的招牌 塔林塔林占地约1.4万平方米,是国内最大的塔林，有砖、石和砖石混合结构的各类墓塔。自唐贞元七年至清嘉庆八年，原有砖基塔500多座，今存232座，其中唐塔2座，宋塔2座，金塔7座，元塔43座，明塔139座，清塔10座，当代塔2座，年代不清塔27座，另有残塔和塔基35处。有单层单檐塔、单层密檐塔、印度窣堵坡塔和各式喇嘛塔等。 塔林的形制层级，高低大小，除了各个历史时期的风尚和具体情况如战争时代，改朝换代等影响，还体现着逝者生前在佛教界的地位、成就和威望。 这些塔的式样繁多，造型各异，是综合研究我国古代砖石建筑和雕刻艺术的宝库。它们大多数是用砖石砌成，亦有用整石凿制而成。塔体上往往刻有精美的图案和浮雕。塔铭内容更加丰富，每座塔正面都有塔额，标识塔主名号；有的塔后还有塔铭，几位有较大影响的高僧塔边，还专门树立碑石，详细记载塔主的生平事迹，嗣法传承，以及立塔人，立塔年代等内容。 塔林里塔的层次只有一、三、五、七四种层次，最高可达15米，造型有正方形、长方形、六角形、圆形、柱形、锥体、瓶体、喇叭体等。所以塔的形制层级、高低大小、砖石建筑和雕刻艺术的不同，都体现着逝者生前在佛教中的地位、成就和威望高低。少林寺少林寺人山人海，但是个人感觉没什么看点，就进去看了一下藏经阁，和大部分寺庙一样，没什么特别之处。 最后附上一张下山路上的嵩山红叶]]></content>
      <categories>
        <category>游记</category>
      </categories>
      <tags>
        <tag>旅行</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[黄河风景名胜区]]></title>
    <url>%2F2015%2F10%2F03%2F%E6%B8%B8%E8%AE%B0%2F%E9%BB%84%E6%B2%B3%E9%A3%8E%E6%99%AF%E5%90%8D%E8%83%9C%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[国庆长假的第一站，郑州。因为10月4日唐荣斌一朋友要结婚，所以先到郑州，在这里浪了一天。 黄河上面的快艇，触碰黄河水。 万花丛中过，片叶不沾身。 炎黄二帝 三帝 伏羲太昊陵 前来祈福的人们]]></content>
      <categories>
        <category>游记</category>
      </categories>
  </entry>
</search>
